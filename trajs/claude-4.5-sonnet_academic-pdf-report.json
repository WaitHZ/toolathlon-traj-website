{"pass": true, "messages": [{"role": "user", "content": "I am conducting research on papers for an AI Conference. For each paper, please help me find the full name of the first author, the complete institutional affiliation of the first author exactly as it appears in the paper (including all institutions if multiple are listed, and specifying down to the department level when provided), and the link to the first author\u2019s Google Scholar profile. You need to fill them in the corresponding excel sheet under my workspace.\n"}, {"role": "assistant", "content": "I'll help you find the information about the first authors from the papers in your workspace. Let me start by exploring your workspace to find the Excel file and any papers.", "tool_calls": [{"id": "toolu_01F2UvBPHna4Je9AXjsqtPST", "type": "function", "function": {"name": "terminal-run_command", "arguments": "{\"command\": \"ls -la /workspace/dumps/workspace\"}"}}]}, {"role": "tool", "content": "[{\"type\": \"text\", \"text\": \"total 28\\ndrwxr-xr-x 4 root root 4096 Oct 17 23:01 .\\ndrwxr-xr-x 4 root root 4096 Oct 17 23:01 ..\\ndrwxr-xr-x 2 root root 4096 Oct 17 23:01 .pdf_tools_tempfiles\\ndrwxr-xr-x 2 root root 4096 Oct 17 23:00 arxiv_local_storage\\n-rw-r--r-- 1 root root 9322 Oct 15 15:54 paper_initial.xlsx\\n\", \"annotations\": null}, {\"type\": \"text\", \"text\": \"\\nCommand completed with return code: 0\", \"annotations\": null}]", "tool_call_id": "toolu_01F2UvBPHna4Je9AXjsqtPST"}, {"role": "assistant", "content": "Now let me check the Excel file to see what papers are listed:", "tool_calls": [{"id": "toolu_01JfdV59beeUPRdRbeUKZYmM", "type": "function", "function": {"name": "excel-read_data_from_excel", "arguments": "{\"filepath\": \"/workspace/dumps/workspace/paper_initial.xlsx\", \"sheet_name\": \"Sheet1\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"range\\\": \\\"A1:D7\\\",\\n  \\\"sheet_name\\\": \\\"Sheet1\\\",\\n  \\\"cells\\\": [\\n    {\\n      \\\"address\\\": \\\"A1\\\",\\n      \\\"value\\\": \\\"Title\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B1\\\",\\n      \\\"value\\\": \\\"First Author\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C1\\\",\\n      \\\"value\\\": \\\"Affiliation\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D1\\\",\\n      \\\"value\\\": \\\"Google Scholar Profile\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A2\\\",\\n      \\\"value\\\": \\\"Strategy Coopetition Explains the Emergence and Transience of In-Context Learning\\\",\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B2\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C2\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D2\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A3\\\",\\n      \\\"value\\\": \\\"Model Immunization from a Condition Number Perspective\\\",\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B3\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C3\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D3\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A4\\\",\\n      \\\"value\\\": \\\"Flowing Datasets with Wasserstein over Wasserstein Gradient Flows\\\",\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B4\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C4\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D4\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A5\\\",\\n      \\\"value\\\": \\\"Learning with Expected Signatures: Theory and Applications\\\",\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B5\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C5\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D5\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A6\\\",\\n      \\\"value\\\": \\\"AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\\\",\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B6\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C6\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D6\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A7\\\",\\n      \\\"value\\\": \\\"Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction\\\",\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B7\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C7\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D7\\\",\\n      \\\"value\\\": null,\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_01JfdV59beeUPRdRbeUKZYmM"}, {"role": "assistant", "content": "Good! I can see there are 6 papers that need information filled in. Let me check if there are any PDF files in the workspace:", "tool_calls": [{"id": "toolu_012LubPmji76WSVHgTy6WQdQ", "type": "function", "function": {"name": "terminal-run_command", "arguments": "{\"command\": \"find /workspace/dumps/workspace -name \\\"*.pdf\\\" -type f\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"\\nCommand completed with return code: 0\",\"annotations\":null}", "tool_call_id": "toolu_012LubPmji76WSVHgTy6WQdQ"}, {"role": "assistant", "content": "Let me check the arxiv_local_storage directory:", "tool_calls": [{"id": "toolu_01A8vSTDi12fHrdgZKMrNWjq", "type": "function", "function": {"name": "terminal-run_command", "arguments": "{\"command\": \"ls -la /workspace/dumps/workspace/arxiv_local_storage/\"}"}}]}, {"role": "tool", "content": "[{\"type\": \"text\", \"text\": \"total 8\\ndrwxr-xr-x 2 root root 4096 Oct 17 23:00 .\\ndrwxr-xr-x 4 root root 4096 Oct 17 23:01 ..\\n\", \"annotations\": null}, {\"type\": \"text\", \"text\": \"\\nCommand completed with return code: 0\", \"annotations\": null}]", "tool_call_id": "toolu_01A8vSTDi12fHrdgZKMrNWjq"}, {"role": "assistant", "content": "The papers aren't downloaded yet. Let me search for each paper on arXiv and download them. I'll start by searching for each paper:", "tool_calls": [{"id": "toolu_01GsfVyUWG7T2J9nvG5sV6tF", "type": "function", "function": {"name": "arxiv_local-search_papers", "arguments": "{\"query\": \"Strategy Coopetition Explains the Emergence and Transience of In-Context Learning\", \"max_results\": 3}"}}, {"id": "toolu_0189MiT7MN5wj126fABGxy2X", "type": "function", "function": {"name": "arxiv_local-search_papers", "arguments": "{\"query\": \"Model Immunization from a Condition Number Perspective\", \"max_results\": 3}"}}, {"id": "toolu_01HGyNastTmUa8dAqm9xK2yM", "type": "function", "function": {"name": "arxiv_local-search_papers", "arguments": "{\"query\": \"Flowing Datasets with Wasserstein over Wasserstein Gradient Flows\", \"max_results\": 3}"}}, {"id": "toolu_01Pxy8v8AKKoHGw8TPmB57ef", "type": "function", "function": {"name": "arxiv_local-search_papers", "arguments": "{\"query\": \"Learning with Expected Signatures: Theory and Applications\", \"max_results\": 3}"}}, {"id": "toolu_01Xnr4yv9DywS7eWBAk2mSyx", "type": "function", "function": {"name": "arxiv_local-search_papers", "arguments": "{\"query\": \"AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\", \"max_results\": 3}"}}, {"id": "toolu_01GLUQogX4rtY4hPC6fuJ9wV", "type": "function", "function": {"name": "arxiv_local-search_papers", "arguments": "{\"query\": \"Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction\", \"max_results\": 3}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 3,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2510.14981v1\\\",\\n      \\\"title\\\": \\\"Coupled Diffusion Sampling for Training-Free Multi-View Image Editing\\\",\\n      \\\"authors\\\": [\\n        \\\"Hadi Alzayer\\\",\\n        \\\"Yunzhi Zhang\\\",\\n        \\\"Chen Geng\\\",\\n        \\\"Jia-Bin Huang\\\",\\n        \\\"Jiajun Wu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"We present an inference-time diffusion sampling method to perform multi-view\\\\nconsistent image editing using pre-trained 2D image editing models. These\\\\nmodels can independently produce high-quality edits for each image in a set of\\\\nmulti-view images of a 3D scene or object, but they do not maintain consistency\\\\nacross views. Existing approaches typically address this by optimizing over\\\\nexplicit 3D representations, but they suffer from a lengthy optimization\\\\nprocess and instability under sparse view settings. We propose an implicit 3D\\\\nregularization approach by constraining the generated 2D image sequences to\\\\nadhere to a pre-trained multi-view image distribution. This is achieved through\\\\ncoupled diffusion sampling, a simple diffusion sampling technique that\\\\nconcurrently samples two trajectories from both a multi-view image distribution\\\\nand a 2D edited image distribution, using a coupling term to enforce the\\\\nmulti-view consistency among the generated images. We validate the\\\\neffectiveness and generality of this framework on three distinct multi-view\\\\nimage editing tasks, demonstrating its applicability across various model\\\\narchitectures and highlighting its potential as a general solution for\\\\nmulti-view consistent editing.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:59+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14981v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14981v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14979v1\\\",\\n      \\\"title\\\": \\\"From Pixels to Words -- Towards Native Vision-Language Primitives at Scale\\\",\\n      \\\"authors\\\": [\\n        \\\"Haiwen Diao\\\",\\n        \\\"Mingxuan Li\\\",\\n        \\\"Silei Wu\\\",\\n        \\\"Linjun Dai\\\",\\n        \\\"Xiaohua Wang\\\",\\n        \\\"Hanming Deng\\\",\\n        \\\"Lewei Lu\\\",\\n        \\\"Dahua Lin\\\",\\n        \\\"Ziwei Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The edifice of native Vision-Language Models (VLMs) has emerged as a rising\\\\ncontender to typical modular VLMs, shaped by evolving model architectures and\\\\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\\\\nexploration and promotion: (-) What fundamental constraints set native VLMs\\\\napart from modular ones, and to what extent can these barriers be overcome? (-)\\\\nHow to make research in native VLMs more accessible and democratized, thereby\\\\naccelerating progress in the field. In this paper, we clarify these challenges\\\\nand outline guiding principles for constructing native VLMs. Specifically, one\\\\nnative VLM primitive should: (i) effectively align pixel and word\\\\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\\\\nstrengths of formerly separate vision and language modules; (iii) inherently\\\\nembody various cross-modal properties that support unified vision-language\\\\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\\\\nnative VLMs built from first principles, capable of rivaling top-tier modular\\\\ncounterparts across diverse real-world scenarios. With only 390M image-text\\\\nexamples, NEO efficiently develops visual perception from scratch while\\\\nmitigating vision-language conflicts inside a dense and monolithic model\\\\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\\\\nscalable and powerful native VLMs, paired with a rich set of reusable\\\\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\\\\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14979v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14979v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14980v1\\\",\\n      \\\"title\\\": \\\"Agentic Design of Compositional Machines\\\",\\n      \\\"authors\\\": [\\n        \\\"Wenqian Zhang\\\",\\n        \\\"Weiyang Liu\\\",\\n        \\\"Zhen Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The design of complex machines stands as both a marker of human intelligence\\\\nand a foundation of engineering practice. Given recent advances in large\\\\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\\\\napproach this question through the lens of compositional machine design: a task\\\\nin which machines are assembled from standardized components to meet functional\\\\ndemands like locomotion or manipulation in a simulated physical environment. To\\\\nsupport this investigation, we introduce BesiegeField, a testbed built on the\\\\nmachine-building game Besiege, which enables part-based construction, physical\\\\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\\\\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\\\\nrequired for success, including spatial reasoning, strategic assembly, and\\\\ninstruction-following. As current open-source models fall short, we explore\\\\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\\\\ndataset, conduct RL finetuning experiments, and highlight open challenges at\\\\nthe intersection of language, machine design, and physical reasoning.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\",\\n        \\\"cs.CL\\\",\\n        \\\"cs.CV\\\",\\n        \\\"cs.GR\\\",\\n        \\\"cs.LG\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14980v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14980v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_01GsfVyUWG7T2J9nvG5sV6tF"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 3,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2510.14981v1\\\",\\n      \\\"title\\\": \\\"Coupled Diffusion Sampling for Training-Free Multi-View Image Editing\\\",\\n      \\\"authors\\\": [\\n        \\\"Hadi Alzayer\\\",\\n        \\\"Yunzhi Zhang\\\",\\n        \\\"Chen Geng\\\",\\n        \\\"Jia-Bin Huang\\\",\\n        \\\"Jiajun Wu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"We present an inference-time diffusion sampling method to perform multi-view\\\\nconsistent image editing using pre-trained 2D image editing models. These\\\\nmodels can independently produce high-quality edits for each image in a set of\\\\nmulti-view images of a 3D scene or object, but they do not maintain consistency\\\\nacross views. Existing approaches typically address this by optimizing over\\\\nexplicit 3D representations, but they suffer from a lengthy optimization\\\\nprocess and instability under sparse view settings. We propose an implicit 3D\\\\nregularization approach by constraining the generated 2D image sequences to\\\\nadhere to a pre-trained multi-view image distribution. This is achieved through\\\\ncoupled diffusion sampling, a simple diffusion sampling technique that\\\\nconcurrently samples two trajectories from both a multi-view image distribution\\\\nand a 2D edited image distribution, using a coupling term to enforce the\\\\nmulti-view consistency among the generated images. We validate the\\\\neffectiveness and generality of this framework on three distinct multi-view\\\\nimage editing tasks, demonstrating its applicability across various model\\\\narchitectures and highlighting its potential as a general solution for\\\\nmulti-view consistent editing.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:59+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14981v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14981v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14979v1\\\",\\n      \\\"title\\\": \\\"From Pixels to Words -- Towards Native Vision-Language Primitives at Scale\\\",\\n      \\\"authors\\\": [\\n        \\\"Haiwen Diao\\\",\\n        \\\"Mingxuan Li\\\",\\n        \\\"Silei Wu\\\",\\n        \\\"Linjun Dai\\\",\\n        \\\"Xiaohua Wang\\\",\\n        \\\"Hanming Deng\\\",\\n        \\\"Lewei Lu\\\",\\n        \\\"Dahua Lin\\\",\\n        \\\"Ziwei Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The edifice of native Vision-Language Models (VLMs) has emerged as a rising\\\\ncontender to typical modular VLMs, shaped by evolving model architectures and\\\\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\\\\nexploration and promotion: (-) What fundamental constraints set native VLMs\\\\napart from modular ones, and to what extent can these barriers be overcome? (-)\\\\nHow to make research in native VLMs more accessible and democratized, thereby\\\\naccelerating progress in the field. In this paper, we clarify these challenges\\\\nand outline guiding principles for constructing native VLMs. Specifically, one\\\\nnative VLM primitive should: (i) effectively align pixel and word\\\\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\\\\nstrengths of formerly separate vision and language modules; (iii) inherently\\\\nembody various cross-modal properties that support unified vision-language\\\\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\\\\nnative VLMs built from first principles, capable of rivaling top-tier modular\\\\ncounterparts across diverse real-world scenarios. With only 390M image-text\\\\nexamples, NEO efficiently develops visual perception from scratch while\\\\nmitigating vision-language conflicts inside a dense and monolithic model\\\\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\\\\nscalable and powerful native VLMs, paired with a rich set of reusable\\\\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\\\\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14979v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14979v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14980v1\\\",\\n      \\\"title\\\": \\\"Agentic Design of Compositional Machines\\\",\\n      \\\"authors\\\": [\\n        \\\"Wenqian Zhang\\\",\\n        \\\"Weiyang Liu\\\",\\n        \\\"Zhen Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The design of complex machines stands as both a marker of human intelligence\\\\nand a foundation of engineering practice. Given recent advances in large\\\\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\\\\napproach this question through the lens of compositional machine design: a task\\\\nin which machines are assembled from standardized components to meet functional\\\\ndemands like locomotion or manipulation in a simulated physical environment. To\\\\nsupport this investigation, we introduce BesiegeField, a testbed built on the\\\\nmachine-building game Besiege, which enables part-based construction, physical\\\\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\\\\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\\\\nrequired for success, including spatial reasoning, strategic assembly, and\\\\ninstruction-following. As current open-source models fall short, we explore\\\\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\\\\ndataset, conduct RL finetuning experiments, and highlight open challenges at\\\\nthe intersection of language, machine design, and physical reasoning.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\",\\n        \\\"cs.CL\\\",\\n        \\\"cs.CV\\\",\\n        \\\"cs.GR\\\",\\n        \\\"cs.LG\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14980v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14980v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_0189MiT7MN5wj126fABGxy2X"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 3,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2510.14981v1\\\",\\n      \\\"title\\\": \\\"Coupled Diffusion Sampling for Training-Free Multi-View Image Editing\\\",\\n      \\\"authors\\\": [\\n        \\\"Hadi Alzayer\\\",\\n        \\\"Yunzhi Zhang\\\",\\n        \\\"Chen Geng\\\",\\n        \\\"Jia-Bin Huang\\\",\\n        \\\"Jiajun Wu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"We present an inference-time diffusion sampling method to perform multi-view\\\\nconsistent image editing using pre-trained 2D image editing models. These\\\\nmodels can independently produce high-quality edits for each image in a set of\\\\nmulti-view images of a 3D scene or object, but they do not maintain consistency\\\\nacross views. Existing approaches typically address this by optimizing over\\\\nexplicit 3D representations, but they suffer from a lengthy optimization\\\\nprocess and instability under sparse view settings. We propose an implicit 3D\\\\nregularization approach by constraining the generated 2D image sequences to\\\\nadhere to a pre-trained multi-view image distribution. This is achieved through\\\\ncoupled diffusion sampling, a simple diffusion sampling technique that\\\\nconcurrently samples two trajectories from both a multi-view image distribution\\\\nand a 2D edited image distribution, using a coupling term to enforce the\\\\nmulti-view consistency among the generated images. We validate the\\\\neffectiveness and generality of this framework on three distinct multi-view\\\\nimage editing tasks, demonstrating its applicability across various model\\\\narchitectures and highlighting its potential as a general solution for\\\\nmulti-view consistent editing.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:59+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14981v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14981v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14979v1\\\",\\n      \\\"title\\\": \\\"From Pixels to Words -- Towards Native Vision-Language Primitives at Scale\\\",\\n      \\\"authors\\\": [\\n        \\\"Haiwen Diao\\\",\\n        \\\"Mingxuan Li\\\",\\n        \\\"Silei Wu\\\",\\n        \\\"Linjun Dai\\\",\\n        \\\"Xiaohua Wang\\\",\\n        \\\"Hanming Deng\\\",\\n        \\\"Lewei Lu\\\",\\n        \\\"Dahua Lin\\\",\\n        \\\"Ziwei Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The edifice of native Vision-Language Models (VLMs) has emerged as a rising\\\\ncontender to typical modular VLMs, shaped by evolving model architectures and\\\\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\\\\nexploration and promotion: (-) What fundamental constraints set native VLMs\\\\napart from modular ones, and to what extent can these barriers be overcome? (-)\\\\nHow to make research in native VLMs more accessible and democratized, thereby\\\\naccelerating progress in the field. In this paper, we clarify these challenges\\\\nand outline guiding principles for constructing native VLMs. Specifically, one\\\\nnative VLM primitive should: (i) effectively align pixel and word\\\\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\\\\nstrengths of formerly separate vision and language modules; (iii) inherently\\\\nembody various cross-modal properties that support unified vision-language\\\\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\\\\nnative VLMs built from first principles, capable of rivaling top-tier modular\\\\ncounterparts across diverse real-world scenarios. With only 390M image-text\\\\nexamples, NEO efficiently develops visual perception from scratch while\\\\nmitigating vision-language conflicts inside a dense and monolithic model\\\\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\\\\nscalable and powerful native VLMs, paired with a rich set of reusable\\\\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\\\\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14979v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14979v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14980v1\\\",\\n      \\\"title\\\": \\\"Agentic Design of Compositional Machines\\\",\\n      \\\"authors\\\": [\\n        \\\"Wenqian Zhang\\\",\\n        \\\"Weiyang Liu\\\",\\n        \\\"Zhen Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The design of complex machines stands as both a marker of human intelligence\\\\nand a foundation of engineering practice. Given recent advances in large\\\\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\\\\napproach this question through the lens of compositional machine design: a task\\\\nin which machines are assembled from standardized components to meet functional\\\\ndemands like locomotion or manipulation in a simulated physical environment. To\\\\nsupport this investigation, we introduce BesiegeField, a testbed built on the\\\\nmachine-building game Besiege, which enables part-based construction, physical\\\\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\\\\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\\\\nrequired for success, including spatial reasoning, strategic assembly, and\\\\ninstruction-following. As current open-source models fall short, we explore\\\\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\\\\ndataset, conduct RL finetuning experiments, and highlight open challenges at\\\\nthe intersection of language, machine design, and physical reasoning.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\",\\n        \\\"cs.CL\\\",\\n        \\\"cs.CV\\\",\\n        \\\"cs.GR\\\",\\n        \\\"cs.LG\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14980v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14980v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_01HGyNastTmUa8dAqm9xK2yM"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 3,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2510.14981v1\\\",\\n      \\\"title\\\": \\\"Coupled Diffusion Sampling for Training-Free Multi-View Image Editing\\\",\\n      \\\"authors\\\": [\\n        \\\"Hadi Alzayer\\\",\\n        \\\"Yunzhi Zhang\\\",\\n        \\\"Chen Geng\\\",\\n        \\\"Jia-Bin Huang\\\",\\n        \\\"Jiajun Wu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"We present an inference-time diffusion sampling method to perform multi-view\\\\nconsistent image editing using pre-trained 2D image editing models. These\\\\nmodels can independently produce high-quality edits for each image in a set of\\\\nmulti-view images of a 3D scene or object, but they do not maintain consistency\\\\nacross views. Existing approaches typically address this by optimizing over\\\\nexplicit 3D representations, but they suffer from a lengthy optimization\\\\nprocess and instability under sparse view settings. We propose an implicit 3D\\\\nregularization approach by constraining the generated 2D image sequences to\\\\nadhere to a pre-trained multi-view image distribution. This is achieved through\\\\ncoupled diffusion sampling, a simple diffusion sampling technique that\\\\nconcurrently samples two trajectories from both a multi-view image distribution\\\\nand a 2D edited image distribution, using a coupling term to enforce the\\\\nmulti-view consistency among the generated images. We validate the\\\\neffectiveness and generality of this framework on three distinct multi-view\\\\nimage editing tasks, demonstrating its applicability across various model\\\\narchitectures and highlighting its potential as a general solution for\\\\nmulti-view consistent editing.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:59+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14981v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14981v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14979v1\\\",\\n      \\\"title\\\": \\\"From Pixels to Words -- Towards Native Vision-Language Primitives at Scale\\\",\\n      \\\"authors\\\": [\\n        \\\"Haiwen Diao\\\",\\n        \\\"Mingxuan Li\\\",\\n        \\\"Silei Wu\\\",\\n        \\\"Linjun Dai\\\",\\n        \\\"Xiaohua Wang\\\",\\n        \\\"Hanming Deng\\\",\\n        \\\"Lewei Lu\\\",\\n        \\\"Dahua Lin\\\",\\n        \\\"Ziwei Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The edifice of native Vision-Language Models (VLMs) has emerged as a rising\\\\ncontender to typical modular VLMs, shaped by evolving model architectures and\\\\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\\\\nexploration and promotion: (-) What fundamental constraints set native VLMs\\\\napart from modular ones, and to what extent can these barriers be overcome? (-)\\\\nHow to make research in native VLMs more accessible and democratized, thereby\\\\naccelerating progress in the field. In this paper, we clarify these challenges\\\\nand outline guiding principles for constructing native VLMs. Specifically, one\\\\nnative VLM primitive should: (i) effectively align pixel and word\\\\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\\\\nstrengths of formerly separate vision and language modules; (iii) inherently\\\\nembody various cross-modal properties that support unified vision-language\\\\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\\\\nnative VLMs built from first principles, capable of rivaling top-tier modular\\\\ncounterparts across diverse real-world scenarios. With only 390M image-text\\\\nexamples, NEO efficiently develops visual perception from scratch while\\\\nmitigating vision-language conflicts inside a dense and monolithic model\\\\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\\\\nscalable and powerful native VLMs, paired with a rich set of reusable\\\\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\\\\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14979v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14979v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14980v1\\\",\\n      \\\"title\\\": \\\"Agentic Design of Compositional Machines\\\",\\n      \\\"authors\\\": [\\n        \\\"Wenqian Zhang\\\",\\n        \\\"Weiyang Liu\\\",\\n        \\\"Zhen Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The design of complex machines stands as both a marker of human intelligence\\\\nand a foundation of engineering practice. Given recent advances in large\\\\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\\\\napproach this question through the lens of compositional machine design: a task\\\\nin which machines are assembled from standardized components to meet functional\\\\ndemands like locomotion or manipulation in a simulated physical environment. To\\\\nsupport this investigation, we introduce BesiegeField, a testbed built on the\\\\nmachine-building game Besiege, which enables part-based construction, physical\\\\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\\\\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\\\\nrequired for success, including spatial reasoning, strategic assembly, and\\\\ninstruction-following. As current open-source models fall short, we explore\\\\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\\\\ndataset, conduct RL finetuning experiments, and highlight open challenges at\\\\nthe intersection of language, machine design, and physical reasoning.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\",\\n        \\\"cs.CL\\\",\\n        \\\"cs.CV\\\",\\n        \\\"cs.GR\\\",\\n        \\\"cs.LG\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14980v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14980v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_01Pxy8v8AKKoHGw8TPmB57ef"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 3,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2510.14981v1\\\",\\n      \\\"title\\\": \\\"Coupled Diffusion Sampling for Training-Free Multi-View Image Editing\\\",\\n      \\\"authors\\\": [\\n        \\\"Hadi Alzayer\\\",\\n        \\\"Yunzhi Zhang\\\",\\n        \\\"Chen Geng\\\",\\n        \\\"Jia-Bin Huang\\\",\\n        \\\"Jiajun Wu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"We present an inference-time diffusion sampling method to perform multi-view\\\\nconsistent image editing using pre-trained 2D image editing models. These\\\\nmodels can independently produce high-quality edits for each image in a set of\\\\nmulti-view images of a 3D scene or object, but they do not maintain consistency\\\\nacross views. Existing approaches typically address this by optimizing over\\\\nexplicit 3D representations, but they suffer from a lengthy optimization\\\\nprocess and instability under sparse view settings. We propose an implicit 3D\\\\nregularization approach by constraining the generated 2D image sequences to\\\\nadhere to a pre-trained multi-view image distribution. This is achieved through\\\\ncoupled diffusion sampling, a simple diffusion sampling technique that\\\\nconcurrently samples two trajectories from both a multi-view image distribution\\\\nand a 2D edited image distribution, using a coupling term to enforce the\\\\nmulti-view consistency among the generated images. We validate the\\\\neffectiveness and generality of this framework on three distinct multi-view\\\\nimage editing tasks, demonstrating its applicability across various model\\\\narchitectures and highlighting its potential as a general solution for\\\\nmulti-view consistent editing.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:59+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14981v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14981v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14979v1\\\",\\n      \\\"title\\\": \\\"From Pixels to Words -- Towards Native Vision-Language Primitives at Scale\\\",\\n      \\\"authors\\\": [\\n        \\\"Haiwen Diao\\\",\\n        \\\"Mingxuan Li\\\",\\n        \\\"Silei Wu\\\",\\n        \\\"Linjun Dai\\\",\\n        \\\"Xiaohua Wang\\\",\\n        \\\"Hanming Deng\\\",\\n        \\\"Lewei Lu\\\",\\n        \\\"Dahua Lin\\\",\\n        \\\"Ziwei Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The edifice of native Vision-Language Models (VLMs) has emerged as a rising\\\\ncontender to typical modular VLMs, shaped by evolving model architectures and\\\\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\\\\nexploration and promotion: (-) What fundamental constraints set native VLMs\\\\napart from modular ones, and to what extent can these barriers be overcome? (-)\\\\nHow to make research in native VLMs more accessible and democratized, thereby\\\\naccelerating progress in the field. In this paper, we clarify these challenges\\\\nand outline guiding principles for constructing native VLMs. Specifically, one\\\\nnative VLM primitive should: (i) effectively align pixel and word\\\\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\\\\nstrengths of formerly separate vision and language modules; (iii) inherently\\\\nembody various cross-modal properties that support unified vision-language\\\\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\\\\nnative VLMs built from first principles, capable of rivaling top-tier modular\\\\ncounterparts across diverse real-world scenarios. With only 390M image-text\\\\nexamples, NEO efficiently develops visual perception from scratch while\\\\nmitigating vision-language conflicts inside a dense and monolithic model\\\\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\\\\nscalable and powerful native VLMs, paired with a rich set of reusable\\\\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\\\\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14979v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14979v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14980v1\\\",\\n      \\\"title\\\": \\\"Agentic Design of Compositional Machines\\\",\\n      \\\"authors\\\": [\\n        \\\"Wenqian Zhang\\\",\\n        \\\"Weiyang Liu\\\",\\n        \\\"Zhen Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The design of complex machines stands as both a marker of human intelligence\\\\nand a foundation of engineering practice. Given recent advances in large\\\\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\\\\napproach this question through the lens of compositional machine design: a task\\\\nin which machines are assembled from standardized components to meet functional\\\\ndemands like locomotion or manipulation in a simulated physical environment. To\\\\nsupport this investigation, we introduce BesiegeField, a testbed built on the\\\\nmachine-building game Besiege, which enables part-based construction, physical\\\\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\\\\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\\\\nrequired for success, including spatial reasoning, strategic assembly, and\\\\ninstruction-following. As current open-source models fall short, we explore\\\\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\\\\ndataset, conduct RL finetuning experiments, and highlight open challenges at\\\\nthe intersection of language, machine design, and physical reasoning.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\",\\n        \\\"cs.CL\\\",\\n        \\\"cs.CV\\\",\\n        \\\"cs.GR\\\",\\n        \\\"cs.LG\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14980v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14980v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_01Xnr4yv9DywS7eWBAk2mSyx"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 3,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2510.14981v1\\\",\\n      \\\"title\\\": \\\"Coupled Diffusion Sampling for Training-Free Multi-View Image Editing\\\",\\n      \\\"authors\\\": [\\n        \\\"Hadi Alzayer\\\",\\n        \\\"Yunzhi Zhang\\\",\\n        \\\"Chen Geng\\\",\\n        \\\"Jia-Bin Huang\\\",\\n        \\\"Jiajun Wu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"We present an inference-time diffusion sampling method to perform multi-view\\\\nconsistent image editing using pre-trained 2D image editing models. These\\\\nmodels can independently produce high-quality edits for each image in a set of\\\\nmulti-view images of a 3D scene or object, but they do not maintain consistency\\\\nacross views. Existing approaches typically address this by optimizing over\\\\nexplicit 3D representations, but they suffer from a lengthy optimization\\\\nprocess and instability under sparse view settings. We propose an implicit 3D\\\\nregularization approach by constraining the generated 2D image sequences to\\\\nadhere to a pre-trained multi-view image distribution. This is achieved through\\\\ncoupled diffusion sampling, a simple diffusion sampling technique that\\\\nconcurrently samples two trajectories from both a multi-view image distribution\\\\nand a 2D edited image distribution, using a coupling term to enforce the\\\\nmulti-view consistency among the generated images. We validate the\\\\neffectiveness and generality of this framework on three distinct multi-view\\\\nimage editing tasks, demonstrating its applicability across various model\\\\narchitectures and highlighting its potential as a general solution for\\\\nmulti-view consistent editing.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:59+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14981v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14981v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14979v1\\\",\\n      \\\"title\\\": \\\"From Pixels to Words -- Towards Native Vision-Language Primitives at Scale\\\",\\n      \\\"authors\\\": [\\n        \\\"Haiwen Diao\\\",\\n        \\\"Mingxuan Li\\\",\\n        \\\"Silei Wu\\\",\\n        \\\"Linjun Dai\\\",\\n        \\\"Xiaohua Wang\\\",\\n        \\\"Hanming Deng\\\",\\n        \\\"Lewei Lu\\\",\\n        \\\"Dahua Lin\\\",\\n        \\\"Ziwei Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The edifice of native Vision-Language Models (VLMs) has emerged as a rising\\\\ncontender to typical modular VLMs, shaped by evolving model architectures and\\\\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\\\\nexploration and promotion: (-) What fundamental constraints set native VLMs\\\\napart from modular ones, and to what extent can these barriers be overcome? (-)\\\\nHow to make research in native VLMs more accessible and democratized, thereby\\\\naccelerating progress in the field. In this paper, we clarify these challenges\\\\nand outline guiding principles for constructing native VLMs. Specifically, one\\\\nnative VLM primitive should: (i) effectively align pixel and word\\\\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\\\\nstrengths of formerly separate vision and language modules; (iii) inherently\\\\nembody various cross-modal properties that support unified vision-language\\\\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\\\\nnative VLMs built from first principles, capable of rivaling top-tier modular\\\\ncounterparts across diverse real-world scenarios. With only 390M image-text\\\\nexamples, NEO efficiently develops visual perception from scratch while\\\\nmitigating vision-language conflicts inside a dense and monolithic model\\\\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\\\\nscalable and powerful native VLMs, paired with a rich set of reusable\\\\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\\\\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.CV\\\",\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14979v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14979v1\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"2510.14980v1\\\",\\n      \\\"title\\\": \\\"Agentic Design of Compositional Machines\\\",\\n      \\\"authors\\\": [\\n        \\\"Wenqian Zhang\\\",\\n        \\\"Weiyang Liu\\\",\\n        \\\"Zhen Liu\\\"\\n      ],\\n      \\\"abstract\\\": \\\"The design of complex machines stands as both a marker of human intelligence\\\\nand a foundation of engineering practice. Given recent advances in large\\\\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\\\\napproach this question through the lens of compositional machine design: a task\\\\nin which machines are assembled from standardized components to meet functional\\\\ndemands like locomotion or manipulation in a simulated physical environment. To\\\\nsupport this investigation, we introduce BesiegeField, a testbed built on the\\\\nmachine-building game Besiege, which enables part-based construction, physical\\\\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\\\\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\\\\nrequired for success, including spatial reasoning, strategic assembly, and\\\\ninstruction-following. As current open-source models fall short, we explore\\\\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\\\\ndataset, conduct RL finetuning experiments, and highlight open challenges at\\\\nthe intersection of language, machine design, and physical reasoning.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\",\\n        \\\"cs.CL\\\",\\n        \\\"cs.CV\\\",\\n        \\\"cs.GR\\\",\\n        \\\"cs.LG\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-10-16T17:59:58+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2510.14980v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2510.14980v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_01GLUQogX4rtY4hPC6fuJ9wV"}, {"role": "assistant", "content": "The searches aren't returning the exact papers. Let me try more specific searches with quotes and different approaches:", "tool_calls": [{"id": "toolu_012uVXY8dDGqtUzq546268Yr", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Strategy Coopetition Explains the Emergence and Transience of In-Context Learning\\\" arxiv\", \"num_results\": 5}"}}, {"id": "toolu_013rY6JHtJwooRtZdiHgpy21", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Model Immunization from a Condition Number Perspective\\\" arxiv\", \"num_results\": 5}"}}, {"id": "toolu_01Q28fR4ivabosPAzNjPXVWV", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Flowing Datasets with Wasserstein over Wasserstein Gradient Flows\\\" arxiv\", \"num_results\": 5}"}}]}, {"role": "tool", "content": "Title: Strategy Coopetition Explains the Emergence and ...\nLink: https://arxiv.org/abs/2503.05631\nSnippet: by AK Singh \u00b7 2025 \u00b7 Cited by 9 \u2014 Abstract page for arXiv paper 2503.05631: Strategy Coopetition Explains the Emergence and Transience of In-Context Learning.\nSitelinks: No sitelinks\n\nTitle: arXiv:2503.05631v2 [cs.LG] 10 Mar 2025\nLink: https://arxiv.org/pdf/2503.05631?\nSnippet: by AK Singh \u00b7 2025 \u00b7 Cited by 9 \u2014 Strategy coopetition explains the emergence and transience of in-context learning. 2015), before being input to the transformer (Singh et ...\nSitelinks: No sitelinks\n\nTitle: Revision History for Strategy Coopetition Explains the...\nLink: https://openreview.net/revisions?id=ADEnKpNjF7\nSnippet: Title: Strategy Coopetition Explains the Emergence and Transience of In-Context Learning. Authors: Aaditya K. Singh, Ted Moskovitz, Sara Dragutinovic, Felix ...\nSitelinks: No sitelinks\n\nTitle: Strategy Coopetition Explains the Emergence and Transience of ...\nLink: https://chatpaper.com/chatpaper/paper/165004\nSnippet: 1. Strategy Coopetition Explains the Emergence and Transience of In-Context Learning \u00b7 ChatDOC. ICML 202518 Jun 2025. Aaditya K Singh, Ted Moskovitz, Sara ...\nSitelinks: No sitelinks\n\nTitle: [Literature Review] Strategy Coopetition Explains the ...\nLink: https://www.themoonlight.io/en/review/strategy-coopetition-explains-the-emergence-and-transience-of-in-context-learning\nSnippet: The paper titled \"Strategy Coopetition Explains the Emergence and Transience of In-Context Learning ... https://arxiv.org/pdf/2503.05631.\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_012uVXY8dDGqtUzq546268Yr"}, {"role": "tool", "content": "Title: Model Immunization from a Condition Number Perspective\nLink: https://arxiv.org/abs/2505.23760\nSnippet: Model Immunization from a Condition Number Perspective. Authors:Amber Yijia Zheng, Cedar Site Bai, Brian Bullins, Raymond A. Yeh.\nSitelinks: No sitelinks\n\nTitle: Model Immunization from a Condition Number Perspective\nLink: https://arxiv.org/html/2505.23760v1\nSnippet: Model Immunization from a Condition Number Perspective. Report issue ... arXiv preprint arXiv:1308.3432, 2013. Bengio et al. (2017) ...\nSitelinks: No sitelinks\n\nTitle: Model Immunization from a Condition Number Perspective\nLink: https://arxiv.org/pdf/2505.23760\nSnippet: Model Immunization from a Condition Number Perspective. Norm ratio ... arXiv preprint arXiv:1911.03030, 2019. He, K., Zhang, X., Ren, S ...\nSitelinks: No sitelinks\n\nTitle: Model Immunization from a Condition Number Perspective\nLink: https://www.amberyzheng.com/immu_cond_num/\nSnippet: Model Immunization from a Condition Number Perspective ... Summary: We provide a theoretical framework for model immunization, showing how the condition number of ...\nSitelinks: No sitelinks\n\nTitle: Model Immunization from a Condition Number Perspective\nLink: https://icml.cc/virtual/2025/poster/43720\nSnippet: Model Immunization from a Condition Number Perspective. Amber Yijia Zheng ... arXiv preprint arXiv:1308.3432, 2013. Bengio, Y., Goodfellow, I., and ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_013rY6JHtJwooRtZdiHgpy21"}, {"role": "tool", "content": "Title: [2506.07534] Flowing Datasets with Wasserstein over ...\nLink: https://arxiv.org/abs/2506.07534\nSnippet: by C Bonet \u00b7 2025 \u00b7 Cited by 6 \u2014 Flowing Datasets with Wasserstein over Wasserstein Gradient Flows. Authors:Cl\u00e9ment Bonet, Christophe Vauthier, Anna Korba.\nSitelinks: No sitelinks\n\nTitle: Flowing Datasets with Wasserstein over Wasserstein Gradient ...\nLink: https://arxiv.org/html/2506.07534v1\nSnippet: arXiv:2506.07534v1 [cs.LG] 09 Jun 2025. Flowing Datasets with Wasserstein over Wasserstein Gradient Flows. Report issue for preceding element. Cl\u00e9ment Bonet ...\nSitelinks: No sitelinks\n\nTitle: Flowing Datasets with Wasserstein over Wasserstein Gradient ...\nLink: https://clbonet.github.io/pdf/Slides/Slides___UBC___18_07_2025.pdf\nSnippet: by C Bonet \u00b7 Cited by 4 \u2014 Hierarchical Integral Probability Metrics: A distance on random probability measures with low sample complexity. arXiv preprint arXiv:2402.00423 ...\nSitelinks: No sitelinks\n\nTitle: ICML Poster Flowing Datasets with Wasserstein over ...\nLink: https://icml.cc/virtual/2025/poster/45752\nSnippet: Flowing Datasets with Wasserstein over Wasserstein Gradient Flows \u00b7 1. Introduction \u00b7 2. Background \u00b7 3. Wasserstein over Wasserstein Space \u00b7 4. WoW Gradient Flows.\nSitelinks: No sitelinks\n\nTitle: (PDF) Flowing Datasets with Wasserstein over ...\nLink: https://www.researchgate.net/publication/392529942_Flowing_Datasets_with_Wasserstein_over_Wasserstein_Gradient_Flows\nSnippet: Flowing Datasets with Wasserstein over Wasserstein Gradient Flows. June 2025. DOI:10.48550/arXiv.2506.07534. License; CC BY 4.0. Authors: Cl\u00e9ment Bonet at ENSAE.\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_01Q28fR4ivabosPAzNjPXVWV"}, {"role": "assistant", "content": "Great! Now I have the arXiv IDs. Let me search for the remaining papers:", "tool_calls": [{"id": "toolu_0143X7wcmKgk7kxXBPZbWW5y", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Learning with Expected Signatures: Theory and Applications\\\" arxiv\", \"num_results\": 5}"}}, {"id": "toolu_016shVrNS8S1oxUihgNyDAWr", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\\\" arxiv\", \"num_results\": 5}"}}, {"id": "toolu_01SyDp4uZg3g9sesqP3sgsZR", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction\\\" arxiv\", \"num_results\": 5}"}}]}, {"role": "tool", "content": "Title: Learning with Expected Signatures: Theory and Applications\nLink: https://arxiv.org/abs/2505.20465\nSnippet: by L Lucchese \u00b7 2025 \u2014 Abstract page for arXiv paper 2505.20465: Learning with Expected Signatures: Theory and Applications.\nSitelinks: No sitelinks\n\nTitle: Learning with Expected Signatures: Theory and Applications\nLink: https://arxiv.org/pdf/2505.20465\nSnippet: by L Lucchese \u00b7 2025 \u2014 Learning with Expected Signatures: Theory and Applications deduce this limit is the same as its P-limit, i.e. Sk(X)[0,T ]. To show the ...\nSitelinks: No sitelinks\n\nTitle: (PDF) Learning with Expected Signatures: Theory and Applications\nLink: https://www.researchgate.net/publication/392134299_Learning_with_Expected_Signatures_Theory_and_Applications\nSnippet: Content may be subject to copyright. arXiv:2505.20465v1 [stat.ML] 26 May 2025. Learning with Expected Signatures: Theory and Applications. Lorenzo Lucchese 1 ...\nSitelinks: No sitelinks\n\nTitle: Learning with Expected Signatures: Theory and Applications ...\nLink: https://ribbitribbit.co/paper/arxiv.2505.20465-Learning-with-Expected-Signatures-Theory-and-Applications\nSnippet: Learning with Expected Signatures: Theory and Applications. By Lorenzo Lucchese, Almut E. D. Veraart | Learn about this paper\u2014or listen like a podcast\u2014on ...\nSitelinks: No sitelinks\n\nTitle: Learning with Expected Signatures: Theory and Applications\nLink: https://chatpaper.com/paper/164958\nSnippet: 1. Learning with Expected Signatures: Theory and Applications \u00b7 ChatDOC. ICML 202518 Jun 2025. Lorenzo Lucchese, Mikko S. Pakkanen, Almut E. D. Veraart.\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_0143X7wcmKgk7kxXBPZbWW5y"}, {"role": "tool", "content": "Title: A Multi-Agent LLM Framework for Full-Pipeline AutoML\nLink: https://arxiv.org/abs/2410.02958\nSnippet: by P Trirat \u00b7 2024 \u00b7 Cited by 47 \u2014 AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Authors:Patara Trirat, Wonyong Jeong, Sung Ju Hwang.\nSitelinks: No sitelinks\n\nTitle: A Multi-Agent LLM Framework for Full-Pipeline AutoML\nLink: https://arxiv.org/pdf/2410.02958\nSnippet: by P Trirat \u00b7 2024 \u00b7 Cited by 47 \u2014 AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Table 2. Summary of downstream tasks and datasets. Data Modality. Downstream Task. Dataset ...\nSitelinks: No sitelinks\n\nTitle: A Multi-Agent LLM Framework for Full-Pipeline AutoML\nLink: https://icml.cc/virtual/2025/poster/44029\nSnippet: AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Patara ... arXiv preprint arXiv:2303.08774, 2023. 3, 7. Baek, J., Jauhar, S. K. ...\nSitelinks: No sitelinks\n\nTitle: A Multi-Agent LLM Framework for Full-Pipeline AutoML\nLink: https://deepauto-ai.github.io/automl-agent/\nSnippet: AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Patara Trirat1, Wonyong Jeong1, Sung Ju Hwang1,2. 1DeepAuto.ai, 2KAIST Seoul, South Korea\nSitelinks: No sitelinks\n\nTitle: A Multi-Agent LLM Framework for Full-Pipeline AutoML\nLink: https://www.semanticscholar.org/paper/AutoML-Agent%3A-A-Multi-Agent-LLM-Framework-for-Trirat-Jeong/efde8940a0b924e93d35184c4a1e8f9670b94fe7\nSnippet: DOI:10.48550/arXiv.2410.02958; Corpus ID: 273162376. AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML ... Published in arXiv ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_016shVrNS8S1oxUihgNyDAWr"}, {"role": "tool", "content": "Title: Learning Smooth and Expressive Interatomic Potentials for ...\nLink: https://arxiv.org/abs/2502.12147\nSnippet: by X Fu \u00b7 2025 \u00b7 Cited by 51 \u2014 Abstract page for arXiv paper 2502.12147: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction.\nSitelinks: No sitelinks\n\nTitle: Learning Smooth and Expressive Interatomic Potentials for ...\nLink: https://arxiv.org/html/2502.12147v1\nSnippet: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction ... arXiv preprint arXiv:2501.09009, 2025. Artrith ...\nSitelinks: No sitelinks\n\nTitle: Learning Smooth and Expressive Interatomic Potentials for ...\nLink: https://www.researchgate.net/publication/389130711_Learning_Smooth_and_Expressive_Interatomic_Potentials_for_Physical_Property_Prediction\nSnippet: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction. February 2025. DOI:10.48550/arXiv.2502.12147. License ...\nSitelinks: No sitelinks\n\nTitle: Learning Smooth and Expressive Interatomic Potentials for ...\nLink: https://raw.githubusercontent.com/mlresearch/v267/main/assets/fu25h/fu25h.pdf\nSnippet: by X Fu \u00b7 Cited by 51 \u2014 Universal machine learning interatomic potentials. 11. Page 12. Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction are ready ...\nSitelinks: No sitelinks\n\nTitle: Learning Smooth and Expressive Interatomic Potentials for ...\nLink: https://x.com/VBFC/status/1891798768636363045\nSnippet: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction. https://t.co/vsDaMFgviz.\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_01SyDp4uZg3g9sesqP3sgsZR"}, {"role": "assistant", "content": "Perfect! Now I have all the arXiv IDs. Let me download the papers to extract the detailed author information:", "tool_calls": [{"id": "toolu_01MkDS2EUckHrVx9ymzEttbV", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2503.05631\"}"}}, {"id": "toolu_01HqbRbHQdbUgMq6ifJNZQr2", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2505.23760\"}"}}, {"id": "toolu_014ZXaSktPXXadEHdwZUuw6S", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2506.07534\"}"}}, {"id": "toolu_011oMmMiGbZziv7rmD5bhb67", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2505.20465\"}"}}, {"id": "toolu_014mW7dfsanPEro3ifn6prPD", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2410.02958\"}"}}, {"id": "toolu_01Jn1iDogx8J9GRQ6LdrkgTr", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2502.12147\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-10-17T23:01:50.470744\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01MkDS2EUckHrVx9ymzEttbV"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-10-17T23:01:50.572556\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01HqbRbHQdbUgMq6ifJNZQr2"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-10-17T23:01:51.713820\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_014ZXaSktPXXadEHdwZUuw6S"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-10-17T23:02:04.683734\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_011oMmMiGbZziv7rmD5bhb67"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-10-17T23:02:08.819665\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_014mW7dfsanPEro3ifn6prPD"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-10-17T23:02:11.267062\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01Jn1iDogx8J9GRQ6LdrkgTr"}, {"role": "assistant", "content": "The papers are being converted. Let me wait a moment and then check their status:", "tool_calls": [{"id": "toolu_01SbDUQEx5vVfKjugbuLheGG", "type": "function", "function": {"name": "playwright_with_chunk-browser_wait_for", "arguments": "{\"time\": 10}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"Error: No open pages available. Use the \\\"browser_navigate\\\" tool to navigate to a page first.\",\"annotations\":null}", "tool_call_id": "toolu_01SbDUQEx5vVfKjugbuLheGG"}, {"role": "assistant", "content": "Let me check the status of the papers:", "tool_calls": [{"id": "toolu_01UxG4U6csBoJ6ET3iY1Zngr", "type": "function", "function": {"name": "terminal-run_command", "arguments": "{\"command\": \"sleep 15\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"Security violation: Command 'sleep' is not allowed\",\"annotations\":null,\"error\":true}", "tool_call_id": "toolu_01UxG4U6csBoJ6ET3iY1Zngr"}, {"role": "assistant", "content": "Let me check the status of the papers directly:", "tool_calls": [{"id": "toolu_01BQ1cnmviMT7cHmk4dSKfxq", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2503.05631\", \"check_status\": true}"}}, {"id": "toolu_01MKQMhT6ArHAteyAobq62TE", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2505.23760\", \"check_status\": true}"}}, {"id": "toolu_01FPctgYVuuUFNywJLUuYeTz", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2506.07534\", \"check_status\": true}"}}, {"id": "toolu_01UjKLKRnV2L6kCH2qBvMAeK", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2505.20465\", \"check_status\": true}"}}, {"id": "toolu_01L7ZzzvydkV1VF1QXLQGJ1z", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2410.02958\", \"check_status\": true}"}}, {"id": "toolu_016H2nRLYc7U4Mqhm1eVFXwQ", "type": "function", "function": {"name": "arxiv_local-download_paper", "arguments": "{\"paper_id\": \"2502.12147\", \"check_status\": true}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"error\\\", \\\"started_at\\\": \\\"2025-10-17T23:01:50.470744\\\", \\\"completed_at\\\": \\\"2025-10-17T23:01:52.028698\\\", \\\"error\\\": \\\"not a textpage of this page\\\", \\\"message\\\": \\\"Paper conversion error\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01BQ1cnmviMT7cHmk4dSKfxq"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"error\\\", \\\"started_at\\\": \\\"2025-10-17T23:01:50.572556\\\", \\\"completed_at\\\": \\\"2025-10-17T23:02:09.342528\\\", \\\"error\\\": \\\"not a textpage of this page\\\", \\\"message\\\": \\\"Paper conversion error\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01MKQMhT6ArHAteyAobq62TE"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"error\\\", \\\"started_at\\\": \\\"2025-10-17T23:01:51.713820\\\", \\\"completed_at\\\": \\\"2025-10-17T23:02:07.903328\\\", \\\"error\\\": \\\"not a textpage of this page\\\", \\\"message\\\": \\\"Paper conversion error\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01FPctgYVuuUFNywJLUuYeTz"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"error\\\", \\\"started_at\\\": \\\"2025-10-17T23:02:04.683734\\\", \\\"completed_at\\\": \\\"2025-10-17T23:02:11.584585\\\", \\\"error\\\": \\\"not a textpage of this page\\\", \\\"message\\\": \\\"Paper conversion error\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01UjKLKRnV2L6kCH2qBvMAeK"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"error\\\", \\\"started_at\\\": \\\"2025-10-17T23:02:08.819665\\\", \\\"completed_at\\\": \\\"2025-10-17T23:02:17.816784\\\", \\\"error\\\": \\\"not a textpage of this page\\\", \\\"message\\\": \\\"Paper conversion error\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01L7ZzzvydkV1VF1QXLQGJ1z"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"started_at\\\": \\\"2025-10-17T23:02:11.267062\\\", \\\"completed_at\\\": null, \\\"error\\\": null, \\\"message\\\": \\\"Paper conversion converting\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_016H2nRLYc7U4Mqhm1eVFXwQ"}, {"role": "assistant", "content": "The papers are having conversion issues. Let me try to download the PDFs directly and extract the information from them:", "tool_calls": [{"id": "toolu_01HoV5vBRCqhiwjhgmGviM1d", "type": "function", "function": {"name": "terminal-run_command", "arguments": "{\"command\": \"cd /workspace/dumps/workspace && wget -O paper1.pdf \\\"https://arxiv.org/pdf/2503.05631.pdf\\\"\"}"}}]}, {"role": "tool", "content": "[{\"type\": \"text\", \"text\": \"--2025-10-17 23:02:50--  https://arxiv.org/pdf/2503.05631.pdf\\nResolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.67.42, 151.101.131.42, ...\\nConnecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\\nHTTP request sent, awaiting response... 301 Moved Permanently\\nLocation: /pdf/2503.05631 [following]\\n--2025-10-17 23:02:50--  https://arxiv.org/pdf/2503.05631\\nReusing existing connection to arxiv.org:443.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 1818293 (1.7M) [application/pdf]\\nSaving to: \\u2018paper1.pdf\\u2019\\n\\n     0K .......... .......... .......... .......... ..........  2% 15.9M 0s\\n    50K .......... .......... .......... .......... ..........  5% 30.4M 0s\\n   100K .......... .......... .......... .......... ..........  8% 81.3M 0s\\n   150K .......... .......... .......... .......... .......... 11% 14.0M 0s\\n   200K .......... .......... .......... .......... .......... 14%  625M 0s\\n   250K .......... .......... .......... .......... .......... 16%  572M 0s\\n   300K .......... .......... .......... .......... .......... 19% 71.6M 0s\\n   350K .......... .......... .......... .......... .......... 22% 24.8M 0s\\n   400K .......... .......... .......... .......... .......... 25%  671M 0s\\n   450K .......... .......... .......... .......... .......... 28%  737M 0s\\n   500K .......... .......... .......... .......... .......... 30%  736M 0s\\n   550K .......... .......... .......... .......... .......... 33% 40.1M 0s\\n   600K .......... .......... .......... .......... .......... 36% 79.0M 0s\\n   650K .......... .......... .......... .......... .......... 39%  255M 0s\\n   700K .......... .......... .......... .......... .......... 42% 50.4M 0s\\n   750K .......... .......... .......... .......... .......... 45% 28.0M 0s\\n   800K .......... .......... .......... .......... .......... 47% 30.2M 0s\\n   850K .......... .......... .......... .......... .......... 50% 86.7M 0s\\n   900K .......... .......... .......... .......... .......... 53%  405M 0s\\n   950K .......... .......... .......... .......... .......... 56% 41.0M ...[output truncated]\", \"annotations\": null, \"error\": true}, {\"type\": \"text\", \"text\": \"\\nCommand completed with return code: 0\", \"annotations\": null}]", "tool_call_id": "toolu_01HoV5vBRCqhiwjhgmGviM1d"}, {"role": "assistant", "content": "Good! Now let me download the rest and extract information from the PDFs:", "tool_calls": [{"id": "toolu_01SbqH32DE1Px3wi2G8VEncy", "type": "function", "function": {"name": "terminal-run_command", "arguments": "{\"command\": \"cd /workspace/dumps/workspace && wget -q -O paper2.pdf \\\"https://arxiv.org/pdf/2505.23760.pdf\\\" && wget -q -O paper3.pdf \\\"https://arxiv.org/pdf/2506.07534.pdf\\\" && wget -q -O paper4.pdf \\\"https://arxiv.org/pdf/2505.20465.pdf\\\" && wget -q -O paper5.pdf \\\"https://arxiv.org/pdf/2410.02958.pdf\\\" && wget -q -O paper6.pdf \\\"https://arxiv.org/pdf/2502.12147.pdf\\\" && echo \\\"All PDFs downloaded\\\"\"}"}}]}, {"role": "tool", "content": "[{\"type\": \"text\", \"text\": \"All PDFs downloaded\\n\", \"annotations\": null}, {\"type\": \"text\", \"text\": \"\\nCommand completed with return code: 0\", \"annotations\": null}]", "tool_call_id": "toolu_01SbqH32DE1Px3wi2G8VEncy"}, {"role": "assistant", "content": "Great! Now let me extract the first few pages from each PDF to get the author information:", "tool_calls": [{"id": "toolu_013ooCtWncUS2VdpPfPJSJAb", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper1.pdf\", \"start_page\": 1, \"end_page\": 2}"}}, {"id": "toolu_01LBzpca2Kmj56QFyTStD43M", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper2.pdf\", \"start_page\": 1, \"end_page\": 2}"}}, {"id": "toolu_01KczXVLzpwhZLrB8csE89mD", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper3.pdf\", \"start_page\": 1, \"end_page\": 2}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 20\\nExtracted page range: 1-2\\n\\n=== Page 1 ===\\nStrategy Coopetition Explains the Emergence\\nand Transience of In-Context Learning\\nAaditya K. Singh1Ted Moskovitz2Sara Dragutinovi \u00b4c3Felix Hill4Stephanie C. Y. Chan* 4\\nAndrew M. Saxe* 1\\nAbstract\\nIn-context learning (ICL) is a powerful ability that\\nemerges in transformer models, enabling them\\nto learn from context without weight updates.\\nRecent work has established emergent ICL as a\\ntransient phenomenon that can sometimes dis-\\nappear after long training times. In this work,\\nwe sought a mechanistic understanding of these\\ntransient dynamics. Firstly, we find that\u2014after\\nthe disappearance of ICL\u2014the asymptotic strat-\\negy is a remarkable hybrid between in-weights\\nand in-context learning, which we term \u201ccontext-\\nconstrained in-weights learning\u201d (CIWL). CIWL\\nis in competition with ICL, and eventually re-\\nplaces it as the dominant strategy of the model\\n(thus leading to ICL transience). However, we\\nalso find that the two competing strategies actu-\\nallyshare sub-circuits, which gives rise to coop-\\nerative dynamics as well. For example, in our\\nsetup, ICL is unable to emerge quickly on its own,\\nand can only be enabled through the simultaneous\\nslow development of asymptotic CIWL. CIWL\\nthus both cooperates andcompetes with ICL, a\\nphenomenon we term \u201cstrategy coopetition\u201d. We\\npropose a minimal mathematical model that re-\\nproduces these key dynamics and interactions. In-\\nformed by this model, we were able to identify a\\nsetup where ICL is truly emergent and persistent.\\n1. Introduction\\nTransformer-based large language models (LLMs) show an\\nimpressive propensity for in-context learning (ICL)\u2014the\\nability to use inputs at inference time to adapt behavior\\nand solve tasks not seen in training. ICL contrasts with in-\\nweights learning (IWL), which is standard learning through\\n*Equal contribution1Gatsby Computational Neuroscience\\nUnit, University College London2Anthropic AI, work com-\\npleted while at the Gatsby Unit, UCL3University of Oxford\\n4Google DeepMind. Correspondence to: Aaditya K. Singh <aa-\\nditya.singh.21@ucl.ac.uk >.weight updates. ICL is striking not only for its power, but\\nalso because it emerges without being explicitly trained\\nfor (as Brown et al. (2020) first observed, when training\\ntransformer models on internet-scale language corpora.).\\nNewer work has shown that ICL can sometimes in fact\\ndisappear after emerging, i.e. it can be transient over the\\ncourse of training (Singh et al., 2023; Anand et al., 2024;\\nHe et al., 2024).\\nThis evolving picture of ICL necessitates a deeper under-\\nstanding of the dynamics of ICL emergence (and transience).\\nICL is often viewed to be in competition with other strate-\\ngies (Nguyen & Reddy, 2024; Park et al., 2024), such as\\nIWL, with the tradeoff thought to be modulated by data\\nproperties (Chan et al., 2022; 2024), model size (Wei et al.,\\n2023), and/or training time (Singh et al., 2023). While com-\\npetition may explain why ICL gives way to other strategies\\nthrough the course of training, the question remains: why\\ndoes it emerge in the first place (if only to fade away)?\\nIn this work, we aim to extend the mechanistic understand-\\ning of ICL, which currently focuses on induction heads\\n(Olsson et al., 2022) and their emergence dynamics (Singh\\net al., 2024), to a richer dynamical setting involving multiple\\nstrategies cycling in and out over the course of learning. To\\ndo so, we reproduce and investigate the key transience result\\nin a simplified synthetic data setting with a 2-layer attention-\\nonly transformer. Using behavioral evaluators, we find the\\nasymptotic strategy after the disappearance of ICL is not\\npure in-weights learning. Rather, it is a surprising hybrid\\nstrategy that we term context-constrained in-weights learn-\\ning (CIWL, Section 4). The implementation of CIWL takes\\nthe form of skip-trigrams (Elhage et al., 2021) distributed\\nacross multiple heads in a form of superposition (Elhage\\net al., 2022). Perhaps even more remarkably, we find that\\neven though CIWL dominates over ICL asymptotically, both\\nstrategies share critical sub-circuits (Section 5.1), indicating\\ncooperative dynamics between these seemingly competitive\\nmechanisms\u2014a phenomenon we term \u201cstrategy coopeti-\\ntion.\u201d We borrow the term \u201ccoopetition\u201d from game theory,\\nwhere it describes situations where competitors simultane-\\nously cooperate and compete with each other.1Cooperation\\n1A classic historical examples is Hollywood studios in the early\\n1arXiv:2503.05631v2  [cs.LG]  10 Mar 2025\\n\\n=== Page 2 ===\\nStrategy coopetition explains the emergence and transience of in-context learning\\n0 or\\n1\\nxTrain: 24 24Strategy used\\nICLCIWL\\nIWL:\\n37 or\\n24\\na)context queryexample\\noutputs b) c)\\nLayer 1\\n(ICL vs\\nCIWL )\\n24 37rep\\n24rep\\n3724\\nLayer 2 \\\"Induction Head\\\"\\n(ICL + CIWL ) 24\\nICL:\\nCIWL:\\nFlip:37 or\\n41\\n37\\n2441\\n 37\\n0 1\\n37\\n24\\n 37037 or\\n41\\n24\\n37 24\\nFigure 1. (a)Example sequences seen during training and evaluation. Training data is \u201cbursty\u201d, enabling both in-context and in-weights\\nstrategies (the context always contains an exemplar from the same class as the query, but also exemplar-label mappings are fixed throughout\\ntraining). Evaluation sequences (below dotted line) are designed to measure the presence of different strategies. ICL relies on the\\nexemplar-label mapping in context. IWL depends solely on in-weights information. CIWL requires the correct label in context, but not the\\nquery exemplar. The Flip evaluator measures the balance between ICL and CIWL (1.0 means pure ICL, 0.0 means pure CIWL). Bolding\\nindicates OOD exemplar-label pairings. Grayed outputs indicate random selection between the two in-context labels. (b)Accuracy on\\nsequences from (a), over the course of training. \u201cIn-context accuracy\u201d is computed by restricting the network\u2019s outputs to the two labels\\npresent in context\u2014this ensures the same chance level (0.5) for all plotted evaluators. ICL transience is clearly visible in blue. IWL is not\\nshown, as we found little-to-no IWL in the networks (Appendix C.1). We annotate four points: 1. the formation of Layer 2 circuits, the\\ncanonical \u201cinduction head\u201d; 2. ICL strategy dominates network output, as evidenced by peak in the Flip evaluator (red); 3. CIWL strategy\\nmatches strength of ICL, as indicated by 50% performance on Flip evaluator; 4. CIWL strategy dominates network output, leading Flip\\nevaluator (red) to be 0 and CIWL evaluator (green) to be 1. (c)Illustration of competitive (Layer 1) and cooperative (Layer 2) interactions\\nwe find between ICL and CIWL strategies. Both strategies are present in varying amounts through training, as represented by the varying\\nline weights in the Layer 1 circuits: when Layer 1 acts as previous token heads, the network exhibits ICL, but when Layer 1 heads attend\\nto self, the network exhibits CIWL. Crucially, the computation in Layer 2 remains largely unchanged after its initial formation, despite the\\nstrategy switch from ICL to CIWL.\\nenables the emergence of ICL (despite it not being asymp-\\ntotically preferred), while competition leads to its eventual\\ntransience (as previously indicated by Singh et al. (2023)).\\nNotably, ICL emergence can only occur when CIWL is not\\nfully formed (Section 5.4), which may explain the tradeoff\\nseen by Chan et al. (2022): under certain data properties,\\nCIWL forms too \u201cquickly,\u201d preventing ICL emergence.\\nWe formalize our intuitions from this case study into a min-\\nimal mathematical model capturing coopetition dynamics\\nand explaining the transience behavior. Our model moti-\\nvates further experiments to modulate the tradeoff between\\nstrategies through learning, like reducing the asymptotic\\nbias towards one strategy via data properties. For the case\\nof ICL vs CIWL, we find that matching context and query\\nexemplars removes the asymptotic bias towards CIWL and\\nleads to the persistence of the \u201cfaster\u201d ICL strategy.\\nOur work represents a step forward in understanding how\\ndifferent strategies trade off during learning, through mech-\\nanistic investigations on the transience of ICL. We hope our\\nwork inspires further work on such coopetitive, dynamical\\nphenomena and enhances intuitions around how capabilities\\nemerge (and possibly fade) when training transformers.\\n20th century, who competed aggressively for talent and audiences,\\nbut also collaborated to establish industry-wide standards and\\njointly negotiate with labor unions.2. Experimental setup\\n2.1. Training details\\nWe train 2-layer attention-only transformers (Vaswani et al.,\\n2017; Elhage et al., 2021) on a synthetic few-shot learn-\\ning task. We use dmodel = 64 , with 8heads per layer and\\nlearned absolute positional embeddings. As is common in\\nmechanistic work (Olsson et al., 2022; Singh et al., 2024),\\nwe chose this minimal setting as it sufficed to reproduce\\nkey phenomena.2We used the Adam optimizer (Kingma\\n& Ba, 2015) with \u03b21= 0.9,\u03b22= 0.999, a learning rate of\\n10\u22125, and a batch size of 32 sequences. All models were\\ntrained in JAX (Bradbury et al., 2018). All code is open-\\nsourced at https://github .com/aadityasingh/\\nicl-dynamics .\\n2.2. Dataset\\nOur few-shot learning task consists of sequences of\\nexemplar-label pairs, where image exemplars are drawn\\nfrom the Omniglot dataset of handwritten characters (Lake\\net al., 2015). Each character class contains 20 image exem-\\nplars, and is assigned to a different one-hot label. Images\\nwere embedded using a Resnet18 encoder that was pre-\\ntrained on ImageNet (He et al., 2015; Russakovsky et al.,\\n2We still consider various alternative architectures, such as\\nthose with MLPs or RoPE (Su et al., 2021), in Appendix B.\\n2\",\"annotations\":null}", "tool_call_id": "toolu_013ooCtWncUS2VdpPfPJSJAb"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 25\\nExtracted page range: 1-2\\n\\n=== Page 1 ===\\narXiv:2505.23760v1  [cs.LG]  29 May 2025Model Immunization from a Condition Number Perspective\\nAmber Yijia Zheng* 1Cedar Site Bai* 1Brian Bullins1Raymond A. Yeh1\\nAbstract\\nModel immunization aims to pre-train models\\nthat are difficult to fine-tune on harmful tasks\\nwhile retaining their utility on other non-harmful\\ntasks. Though prior work has shown empirical ev-\\nidence for immunizing text-to-image models, the\\nkey understanding of when immunization is pos-\\nsible and a precise definition of an immunized\\nmodel remain unclear. In this work, we pro-\\npose a framework, based on the condition num-\\nber of a Hessian matrix, to analyze model im-\\nmunization for linear models. Building on this\\nframework, we design an algorithm with regular-\\nization terms to control the resulting condition\\nnumbers after pre-training. Empirical results on\\nlinear models and non-linear deep-nets demon-\\nstrate the effectiveness of the proposed algorithm\\non model immunization. The code is available\\nathttps://github.com/amberyzheng/\\nmodel-immunization-cond-num .\\n1. Introduction\\nModel immunization, recently proposed by Zheng & Yeh\\n(2024), studies how to pre-train a model that is more difficult\\nto fine-tune on harmful content, but not others. The aim\\nis to mitigate the risk of misuse (Brundage et al., 2018;\\nMarchal et al., 2024) associated with open-sourced models\\nby immunizing them before they are released to the public.\\nZheng & Yeh (2024) focus on immunizing text-to-image\\nmodels, where they formulate immunization as a bi-level op-\\ntimization. Empirically, they show that pre-trained diffusion\\nmodels that undergo immunization are more difficult to fine-\\ntune on a given harmful concept dataset. To quantify this\\ndifficulty, they compare the generation quality of models\\nwith and without immunization after a fixed number of fine-\\ntuning iterations. While the empirical results are promising,\\n*Equal contribution1Department of Computer Science,\\nPurdue University. Correspondence to: Raymond A. Yeh\\n<rayyeh@purdue.edu >.\\nProceedings of the 42ndInternational Conference on Machine\\nLearning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025\\nby the author(s).a definition of an immunized model and the circumstances\\nthat make immunization possible remain unclear.\\nTo tackle this issue, we propose a framework to study\\nmodel immunization using the condition number (Gloub\\n& Van Loan, 1996). The effectiveness of immunization can\\nbe characterized by the condition number of the Hessian\\nmatrix. When using gradient-based methods during fine-\\ntuning, a condition number closer to one indicates faster\\nconvergence (Boyd & Vandenberghe, 2004), i.e., easier to\\nfine-tune. With this perspective, we observe that the ex-\\nistence of an effective immunization for linear models is\\nrelated to the angle between the singular vectors of the\\nharmful fine-tuning dataset\u2019s covariance matrix and the pre-\\ntraining dataset\u2019s covariance matrix.\\nFrom this condition number perspective, we propose an\\nimmunization algorithm to find such a model. In detail,\\nwe propose two additional terms to regularize the condi-\\ntion number during pre-training. Each of the introduced\\nregularization terms can be shown to ensure a monotonic\\nincrease/decrease of the condition number under gradient\\nupdates.\\nBeyond the theoretical results, we empirically validate the\\nproposed algorithm on linear models for regression and\\nimage classification tasks. Lastly, we conduct experiments\\nusing the proposed algorithm on non-linear models, i.e.,\\ndeep-nets. Despite the gap in theory, we observe that the\\nproposed approach remains effective at model immunization\\nacross ResNet (He et al., 2016) and ViT (Dosovitskiy, 2021).\\nOur contributions are summarized as follows:\\n\u2022We introduce a framework based on the condition number\\nto study the task of model immunization. This framework\\nleads to a concrete definition of an immunized model\\nalong with a novel experiment setup and evaluation met-\\nric to compare the quality of different immunization tech-\\nniques.\\n\u2022We propose regularizers to maximize/minimize the con-\\ndition number, with a guaranteed monotonic increase/de-\\ncrease when updated with the gradient-based method.\\n\u2022Together with the task objective and regularizers, we\\ndemonstrate that the proposed algorithm effectively im-\\nmunizes linear models and deep-nets on regression/image\\nclassification tasks.\\n1\\n\\n=== Page 2 ===\\nModel Immunization from a Condition Number Perspective\\n2. Preliminaries\\nThis section provides the background of the condition num-\\nber and its connection to gradient descent. Additionally, we\\nbriefly review transfer learning (Zhuang et al., 2020), as it\\ncan be a technique for misusing open-source models.\\nCondition number and convergence of gradient descent.\\nGiven a general matrix S, the condition number (Gloub &\\nVan Loan, 1996) is defined as\\n\u03ba(S)\u225c\u2225S\u22252\\r\\rS\u2020\\r\\r\\n2=\u03c3max\\nS/\u03c3min\\nS, (1)\\nwhere \u2020is the pseudoinverse and \u03c3Scorresponds to the\\nmax/min singular value of S. The condition number is\\nrelated to the convergence rate of gradient-based algorithms.\\nConsider an optimization problem minwL(w)where L\\nis strongly convex and has a Hessian \u22072Lwith max/min\\nsingular values denoted as \u03c3max/min. In this case, the con-\\nstant step-size steepest descent algorithm has a convergence\\nrate (Bubeck, 2015) of the following\\n\u2225wt\u2212w\u2217\u22252\u2264\\u0012\\n1\u2212\u03c3min\\n\u03c3max\\u0013t\\n\u2225w0\u2212w\u2217\u22252, (2)\\nwhere w\u2217denotes the optimal solution, and wtdenotes the\\nsteepest descent iterate at step t. We can observe that a larger\\ncondition number corresponds to a slower convergence.\\nCondition number regularization. Nenov et al. (2024)\\nproposed a regularizer for minimizing the condition number\\nof some general matrix S\\nRwell(S) =1\\n2\u2225S\u22252\\n2\u22121\\n2p\u2225S\u22252\\nF, (3)\\nin which pis the minimum dimension of S, and the norms\\ncorrespond to the spectral norm and Frobenius norm. They\\nshowed that Rwell(S)is a valid regularizer by proving its\\nnonnegativity, and is an upper bound on log (\u03ba(S)). In\\naddition, they showed that Rwell(S)is differentiable under\\nsome mild conditions, and if updated with gradient descent,\\nit is guaranteed to decrease the condition number monotoni-\\ncally. See Appendix A for the exact statements.\\nDifferent from Nenov et al. (2024), we propose a differen-\\ntiable regularizer that is guaranteed to increase the condi-\\ntion number as an upper bound on 1/log (\u03ba(S)). For model\\nimmunization, instead of a general matrix S, we need to\\nconsider the regularization of the Hessian of linear models\\ncomposed of a feature extractor and a classifier, while pre-\\nserving their differentiability and monotonicity guarantees\\nduring gradient updates to the feature extractor.\\nTransfer learning via linear probing. In this work, we\\nfocus on the transfer learning method of linear probing.\\nGiven a pre-trained feature extractor f\u03b8:RDin\u2192RDhid,\\nlinear probing learns an a linear classifier hw:RDhid\u2192RDoutover the target dataset D={(x,y)}using the frozen\\nfeature extractor f\u03b8. This model learning is formulated as\\nthe following optimization problem\\nmin\\nwL(D,w, \u03b8)\u225cmin\\nwX\\n(x,y)\u2208D\u2113(hw\u25e6f\u03b8(x),y) (4)\\nwhere \u2113denotes a suitable loss function, e.g., cross-entropy.\\nBy keeping \u03b8fixed, the model leverages features learned\\nfrom pre-training task and transfers them to the target task.\\nThis approach is effective when the target dataset is too\\nsmall to train a model from scratch.\\n3. Immunization with Condition Number\\nThe goal of model immunization is to learn a pre-trained\\nmodel g\u03c9\u25e6f\u03b8I, consisting of a classifier g\u03c9and an immu-\\nnized feature extractor f\u03b8I, such that fine-tuning f\u03b8Ion a\\nharmful task is difficult, but not for other tasks. The model\\nshould also maintain a good pre-training task performance.\\nSpecifically, we study the setting when a bad actor uses\\nlinear probing on a pre-trained linear feature extractor with\\ngradient descent.\\nImmunization setting. We denote a pre-training dataset\\nasDP={(x,y)}and a harmful dataset as DH={(x,\u02dcy)}\\nwhere x\u2208RDin. The bad actor performs linear probing us-\\ningDHfollowing Eq. (4)with an \u21132loss. We will focus our\\nanalysis on linear pre-trained feature extractor without di-\\nmensionality reduction, i.e.,f\u03b8\u225cx\u22a4\u03b8with\u03b8\u2208RDin\u00d7Din.\\nDefinition 3.1. Under this setting, a model is said to be\\nimmunized if it satisfies the following:\\n(a)It is more difficult to apply linear probing on the harmful\\ntaskDHusing the immunized feature extractor f\u03b8Ithan\\ndirectly on the input data, i.e.,\\n\u03ba(\u22072\\nwL(DH,w, \u03b8I))\u226b\u03ba(\u22072\\nwL(DH,w,I)), (5)\\nwhere Idenotes the identity matrix.\\n(b)It is not more difficult to apply linear probing on other\\ntasks. As there is only one other task DP, an immunized\\nfeature extractor should have\\n\u03ba(\u22072\\n\u03c9L(DP, \u03c9, \u03b8I))\u2264\u03ba(\u22072\\n\u03c9L(DP, \u03c9,I)). (6)\\nNote: we use \u03c9to denote the classifier parameters of the\\npre-training task and wfor the harmful task.\\n(c)The immunized model should maintain a competitive\\ntask performance on the pre-training dataset DP,i.e.,\\nmin\\n\u03c9,\u03b8L(DP, \u03c9, \u03b8)\u2248min\\n\u03c9L(DP, \u03c9, \u03b8I). (7)\\nFor linear models, as long as \u03b8Iis invertible, exact equality\\ncan be achieved.\\n2\",\"annotations\":null}", "tool_call_id": "toolu_01LBzpca2Kmj56QFyTStD43M"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 57\\nExtracted page range: 1-2\\n\\n=== Page 1 ===\\narXiv:2506.07534v1  [cs.LG]  9 Jun 2025Flowing Datasets with Wasserstein over Wasserstein Gradient Flows\\nCl\u00b4ement Bonet* 1Christophe Vauthier* 2Anna Korba1\\nAbstract\\nMany applications in machine learning involve\\ndata represented as probability distributions. The\\nemergence of such data requires radically novel\\ntechniques to design tractable gradient flows on\\nprobability distributions over this type of (infinite-\\ndimensional) objects. For instance, being able to\\nflow labeled datasets is a core task for applica-\\ntions ranging from domain adaptation to transfer\\nlearning or dataset distillation. In this setting, we\\npropose to represent each class by the associated\\nconditional distribution of features, and to model\\nthe dataset as a mixture distribution supported on\\nthese classes (which are themselves probability\\ndistributions), meaning that labeled datasets can\\nbe seen as probability distributions over proba-\\nbility distributions. We endow this space with a\\nmetric structure from optimal transport, namely\\nthe Wasserstein over Wasserstein (WoW) distance,\\nderive a differential structure on this space, and\\ndefine WoW gradient flows. The latter enables to\\ndesign dynamics over this space that decrease a\\ngiven objective functional. We apply our frame-\\nwork to transfer learning and dataset distillation\\ntasks, leveraging our gradient flow construction\\nas well as novel tractable functionals that take\\nthe form of Maximum Mean Discrepancies with\\nSliced-Wasserstein based kernels between proba-\\nbility distributions.\\n1. Introduction\\nProbability measures provide a powerful way to represent\\nmany data types. For instance, they allow to naturally repre-\\nsent documents (Kusner et al., 2015), genes (Bellazzi et al.,\\n2021), point clouds (Qi et al., 2017; Geuter et al., 2025),\\nimages (Sodini et al., 2025), or single-cell data (Persad et al.,\\n*Equal contribution1ENSAE, CREST, IP Paris2Universit \u00b4e\\nParis-Saclay, Laboratoire de Math \u00b4ematique d\u2019Orsay. Correspon-\\ndence to: Cl \u00b4ement Bonet <clement.bonet@ensae.fr >, Chrisophe\\nVauthier <christophe.vauthier@universite-paris-saclay.fr >.\\nProceedings of the 42ndInternational Conference on Machine\\nLearning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025\\nby the author(s).2023; Haviv et al., 2024b). Remarkably, it has been shown\\nthat one can embed any finite dataset with little or no distor-\\ntion (Andoni et al., 2018; Kratsios et al., 2023) in the Wasser-\\nstein space, i.e., the space of probability distributions ( e.g.,\\nover a Euclidean space) equipped with the Wasserstein-2 dis-\\ntance from Optimal Transport (OT). This has motivated the\\nuse of this space to embed many types of data ranging from\\nwords (Vilnis & McCallum, 2015) to knowledge graphs\\n(He et al., 2015; Wang et al., 2022), graphs (Bojchevski &\\nG\u00a8unnemann, 2018; Petric Maretic et al., 2019), or neuro-\\nscience data (Bonet et al., 2023). Therefore, it is essential to\\ndevelop tools to work on the space of probability measures\\nover probability measures, also known as random measures.\\nIn particular, they provide a natural way to represent labeled\\ndatasets as mixtures (Alvarez-Melis & Fusi, 2020).\\nA natural distance on this space is the Wasserstein over\\nWasserstein distance (WoW) (Nguyen, 2016; Catalano\\n& Lavenant, 2024), also known as the Hierarchical OT\\ndistance, which lifts the Wasserstein distance between prob-\\nability distributions as a ground cost, to define a Wasserstein\\ndistance between random measures. The latter has been used\\nfor generative modeling applications (Dukler et al., 2019),\\ndomain adaptation tasks (El Hamri et al., 2022), comparing\\ndocuments (Yurochkin et al., 2019) or multilevel clustering\\n(Ho et al., 2017). It has also been used to compare Gaussian\\nmixtures (Chen et al., 2018; Delon & Desolneux, 2020;\\nWilson et al., 2024) or generic mixtures (Dusson et al., 2023;\\nChen & Zhang, 2024). However, its poor sample complexity\\nhas motivated the development of alternative distance mea-\\nsures, such as those based on Integral Probability Metrics\\n(Catalano & Lavenant, 2024). Nonetheless, this space pos-\\nsesses a rich Riemannian structure, enabling the definition\\nof concepts like geodesics. This has been leveraged recently\\nby Haviv et al. (2024a) to perform generative modeling over\\nthe space of probability distributions with Flow Matchings.\\nWhile this space naturally supports a range of machine learn-\\ning tasks, optimization methods tailored to it have received\\nlimited attention. Yet, this is important for multiple ap-\\nplications, including variational inference with a Gaussian\\nmixture family (Lambert et al., 2022; Huix et al., 2024),\\ncomputing barycenters (Delon & Desolneux, 2020), or flow-\\ning datasets (Alvarez-Melis & Fusi, 2021), e.g., for domain\\nadaptation, transfer learning (Alvarez-Melis & Fusi, 2021;\\nHua et al., 2023) or dataset distillation (Wang et al., 2018).\\n1\\n\\n=== Page 2 ===\\nFlowing Datasets with Wasserstein over Wasserstein Gradient Flows\\nIn this paper, we propose to leverage the Riemannian struc-\\nture of random measures equipped with the WoW distance,\\nby defining and simulating gradient flows, i.e., paths of ran-\\ndom measures that follow the steepest descent of a given\\nobjective functional.\\nRelated works. An elegant and popular way to perform\\noptimization over probability distributions (over a manifold)\\nis to leverage the Riemannian structure of the Wasserstein\\nspace (Otto, 2001), and to use Wasserstein gradient flows\\n(Ambrosio et al., 2008; Santambrogio, 2017). Several time\\ndiscretizations of these flows have been studied (Jordan\\net al., 1998; Salim et al., 2020; Bonet et al., 2024), and\\nthey have been applied to simulate the flow dynamics of\\nmultiple objectives such as the Kullback-Leibler divergence\\n(Wibisono, 2018; Salim et al., 2020; Diao et al., 2023), the\\nMaximum Mean Discrepancy (MMD) (Arbel et al., 2019;\\nAltekr \u00a8uger et al., 2023; Hertrich et al., 2024a;b) and variants\\nthereof (Glaser et al., 2021; Chen et al., 2024; Neumayer\\net al., 2024; Chazal et al., 2024) or the Sliced-Wasserstein\\ndistance (Liutkus et al., 2019; Du et al., 2023; Bonet et al.,\\n2025). Yet, all these works focus on the case where the prob-\\nability distributions are defined over a finite-dimensional\\nmanifold, e.g. Rd. In practice, simulating these flows\\noften boils down to simulating a particle system in Rd.\\nHence, these works do not address probability distributions\\ndefined on infinite-dimensional spaces, such as the space\\nof probability measures, which is the focus of this work.\\nThe closest works to ours are the ones of Alvarez-Melis &\\nFusi (2021) and Hua et al. (2023). These papers cast labeled\\ndatasets as measures over a product space of the features\\nand the conditional distributions ( i.e., the distributions of\\nthe features of a given class). However, they circumvent the\\nissue of designing gradient flows on this space by modeling\\nthe conditional probabilities as Gaussian distributions, hence\\nparametrized by a mean and covariance, which are finite-\\ndimensional objects. While this enables them to leverage\\nstandard Wasserstein gradient flows, this Gaussian modeling\\nof mixture components is a strong assumption that may not\\ncapture the true shape of many labeled datasets in practice.\\nContributions. In this work, we introduce a principled\\nframework for optimizing functionals over the space of\\nprobability measures on probability measures, leveraging\\nthe Riemannian structure of this space to develop Wasser-\\nstein over Wasserstein (WoW) gradient flows. We provide\\na theoretical construction of the flows, and then a practical\\nimplementation through time discretization using a forward\\nEuler scheme. We also propose a novel functional objective,\\nthat writes as an MMD with kernel between distributions\\nbased on the Sliced-Wasserstein distance, and whose gradi-\\nent flow simulation is tractable. We then apply this scheme\\nto flow datasets viewed as random measures; specifically, asmixtures of probability distributions corresponding to the\\nclass-conditional distributions. We focus on image datasets,\\nand show that the flow enables structured transitions of\\nclasses toward other classes, with applications to transfer\\nlearning and dataset distillation.\\nNotations. For a Riemannian manifold M,d:M \u00d7\\nM \u2192 R+is its geodesic distance. For x\u2208 M , we denote\\nbyTxMthe tangent space at x, and by \u2225 \u00b7 \u2225xthe Rieman-\\nnian metric. We define by TM={(x, v), x\u2208 M andv\u2208\\nTxM} the tangent bundle. We define for (x, v)\u2208TM\\nthe projections \u03c0M(x, v) =xand\u03c0v(x, v) =v.exp :\\nTM \u2192 M is the exponential map. For x\u2208 M , if\\nexpx:TxM \u2192 M is invertible, we note logxits inverse.\\n\u2207anddivrefer to the Riemannian gradient and divergence\\nonM. For a metric space (X, d),P2(X)denotes the space\\nof probability distributions on Xwith second finite mo-\\nments, i.e.,P2(X) ={\u00b5\u2208 P(X),R\\nd(x, o)2d\u00b5(x)<\u221e}\\nwitho\u2208Xsome arbitrary origin. For any \u00b5\u2208 P 2(M),\\nL2(\u00b5, TM)is the set of functions v:M \u2192 TM\\nsuch thatR\\n\u2225v(x)\u22252\\nxd\u00b5(x)<\u221e. For a measurable map\\nT :M \u2192 M , we note by T#\u00b5the pushforward measure.\\nIddenotes the identity map on M.P2,ac(M)\u2282 P 2(M)is\\nthe space of measures absolutely continuous w.r.t. the vol-\\nume measure on M. For\u00b5, \u03bd\u2208 P(X), we denote \u00b5\u226a\u03bdif\\n\u00b5is absolutely continuous w.r.t.\u03bd.\u03a0(\u00b5, \u03bd) ={\u03b3\u2208 P(X\u00d7\\nX), \u03c01\\n#\u03b3=\u00b5, \u03c02\\n#\u03b3=\u03bd}with\u03c0i: (x1, x2)7\u2192xi, is the\\nset of couplings, and \u03a0o(\u00b5, \u03bd)the set of optimal couplings.\\n2. Background\\nWe begin by introducing some background on Optimal\\nTransport (OT) and on Wasserstein Gradient Flows. For the-\\noretical purposes, we provide background on the geometry\\nof (P2(M),W2)withMa Riemannian manifold, as in the\\nnext section, we will rely on results which hold on compact\\nRiemannian manifolds (without boundary). Nonetheless,\\nthe applications will be done for M=Rd. The reader may\\nrefer to Appendix A for more details.\\nOptimal Transport. The Wasserstein distance between\\n\u00b5, \u03bd\u2208 P2(M)is defined as\\nW2\\n2(\u00b5, \u03bd) = inf\\n\u02dc\u03b3\u2208\u03a0(\u00b5,\u03bd)Z\\nd(x, y)2d\u02dc\u03b3(x, y). (1)\\nThe metric space (P2(M),W2)has a Riemannian\\nstructure (Otto, 2001; Erbar, 2010). In particular, if\\nthe log map is well defined \u00b5-almost everywhere (a.e.),\\n(constant-speed) geodesics between \u00b5, \u03bd are defined as\\n\u00b5t=\\u0000\\nexp\u03c01\u25e6(tlog\u03c01\u25e6\u03c02)\\u0001\\n#\u02dc\u03b3with\u02dc\u03b3\u2208\u03a0o(\u00b5, \u03bd)an op-\\ntimal coupling. If \u00b5\u2208 P2,ac(M), there is a map T, namely\\nthe OT map, such that T#\u00b5=\u03bdand\u02dc\u03b3= (Id ,T)#\u00b5by\\nMcCann\u2019s theorem for a wide range of manifolds (McCann,\\n2001; Figalli, 2007). In particular, T = expId\u25e6(\u2212\u2207\u03c6\u00b5,\u03bd)\\n2\",\"annotations\":null}", "tool_call_id": "toolu_01KczXVLzpwhZLrB8csE89mD"}, {"role": "assistant", "content": "Excellent! Now let me continue with the remaining papers:", "tool_calls": [{"id": "toolu_01E5EAuX4T4rTfrTejsSw7Vc", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper4.pdf\", \"start_page\": 1, \"end_page\": 2}"}}, {"id": "toolu_01W5pL6wJa3m5YWRi5hHadmA", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper5.pdf\", \"start_page\": 1, \"end_page\": 2}"}}, {"id": "toolu_01SUgUqxrromgAMGHfN725s3", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper6.pdf\", \"start_page\": 1, \"end_page\": 2}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 61\\nExtracted page range: 1-2\\n\\n=== Page 1 ===\\narXiv:2505.20465v1  [stat.ML]  26 May 2025Learning with Expected Signatures: Theory and Applications\\nLorenzo Lucchese1Mikko S. Pakkanen1Almut E. D. Veraart1\\nAbstract\\nThe expected signature maps a collection of data\\nstreams to a lower dimensional representation,\\nwith a remarkable property: the resulting fea-\\nture tensor can fully characterize the data gener-\\nating distribution. This \u201cmodel-free\u201d embedding\\nhas been successfully leveraged to build multi-\\nple domain-agnostic machine learning (ML) al-\\ngorithms for time series and sequential data. The\\nconvergence results proved in this paper bridge\\nthe gap between the expected signature\u2019s em-\\npirical discrete-time estimator and its theoreti-\\ncal continuous-time value, allowing for a more\\ncomplete probabilistic interpretation of expected\\nsignature-based ML methods. Moreover, when\\nthe data generating process is a martingale, we\\nsuggest a simple modification of the expected sig-\\nnature estimator with significantly lower mean\\nsquared error and empirically demonstrate how it\\ncan be effectively applied to improve predictive\\nperformance.\\n1. Introduction\\nThe signature transform of a stream of data is an infinite but\\ncountable sequence of its \u201citerated integrals\u201d summarizing\\nthe input in a top-down fashion, meaning the informational\\ncontent of its terms decays factorially. Originally introduced\\nby Chen (1954) and serving as a fundamental object of\\nrough path analysis (Lyons et al., 2007), the signature\\nS={S(X)[0,t]\u2208T((Rd)), t\u2208[0, T]},\\nof a path X={Xt, t\u2208[0, T]} \u2208C([0, T],Rd)is a lift\\n(in the sense that it embeds X) to the space of continuous\\nfunctions over the tensor algebra T((Rd))possessing some\\nnice algebraic and geometric properties. When the path is of\\nbounded variation, the signature is defined as the sequence\\n1Department of Mathematics, Imperial College London, Lon-\\ndon, United Kingdom. Correspondence to: Lorenzo Lucchese\\n<lorenzo.lucchese17@imperial.ac.uk, llucchese6@gmail.com >.\\nProceedings of the 42ndInternational Conference on Machine\\nLearning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025\\nby the author(s).of iterated integrals of X, i.e. for t\u2208[0, T], k\u22650\\nSk(X)[0,t]=Z\\n\u00b7\u00b7\u00b7Z\\n0\u2264s1\u2264...\u2264sk\u2264tdXs1\u2297 \u00b7\u00b7\u00b7 \u2297 dXsk.(1)\\nIn many practical applications the path Xis taken to be\\nthe piecewise linear interpolation of a discrete-time stream\\nof data, which is of bounded variation by construction.\\nSignature-based machine learning (ML) approaches (Lyons\\n& McLeod, 2024) thus often restrict the theoretical frame-\\nwork to paths in BV([0, T],Rd). In this setting, two funda-\\nmental properties of the signature that make it a desirable\\nnon-parametric feature extraction method for sequential\\ndata are the characterization result of Hambly & Lyons\\n(2005) and the universality approximation theorem of Levin\\net al. (2016). Moreover, when the path Xis understood\\nas a (realization of a) random process with distribution P\\nover BV([0, T],Rd), the shuffle property of the signature\\nimplies that all moments of the random variable S(X)[0,T]\\nare determined by its expectation\\n\u03d5(T) :=E[S(X)[0,T]]\u2208T((Rd)).\\nA natural question, known as the Hamburger moment prob-\\nlem (Fawcett, 2003), is thus whether the expectation of\\nthe signature characterizes its law (and thus the law of the\\npath). When imposing a probability distribution PonX\\nthe assumption of bounded variation paths becomes quite\\nrestrictive: Brownian motion, the basic building block of\\nmany stochastic models, has paths of infinite variation al-\\nmost surely. Even if we observe a discrete-time stream of\\ndata, we often still would like to define the process Xas\\na latent stochastic process of which we observe the linear\\ninterpolation over some partition \u03c0of[0, T], hereafter de-\\nnoted by X\u03c0. We hence wish to make sense of the signature\\nof a stochastic process Xwith paths of unbounded variation.\\nFor a given path X\u2208C([0, T],Rd)of finite p-variation,\\nonce we \u201clift\u201d the process to a p-rough path (Lyons et al.,\\n2007, Definition 3.11) then the signature SofXis uniquely\\ndefined1. Without delving into the details of rough path\\ntheory, for our purposes it suffices to interpret the choice of\\nlift as fixing a notion of integration with respect to X: the\\nhigher order signatures terms are then understood as iterated\\nintegrals of the path Xdefined in this sense.\\n1This is the first fundamental theorem in the theory of rough\\npaths (Lyons et al., 2007, Theorem 3.7).\\n1\\n\\n=== Page 2 ===\\nLearning with Expected Signatures: Theory and Applications\\nMotivated by the fact that we can only ever observe the\\nprocess Xover a discrete partition \u03c0of[0, T]we restrict our\\nattention to the class of stochastic processes whose lift (and\\nhence signature) can be approximated by the lift (and hence\\nsignature) of the bounded variation path X\u03c0. Following the\\nrough path literature we take such approximation in the p-\\nvariation metric to define the notion of canonical geometric\\nstochastic process , cf. Definition 2.1. In Chevyrev & Lyons\\n(2016); Chevyrev & Oberhauser (2018) the authors provide\\ncharacterization results for the expected signature of canon-\\nical geometric stochastic processes, i.e. conditions under\\nwhich the map P7\u2192E[S(X)[0,T]]is injective. Such charac-\\nterizing property of the expected signature has found practi-\\ncal use in a wide range of applications, ranging from classic\\nML tasks (Lemercier et al., 2021; Triggiano & Romito,\\n2024; Schell & Oberhauser, 2023) to mathematical finance\\n(Lyons et al., 2021; Futter et al., 2023).\\nThe expected signature is thus a highly informative quan-\\ntity and, consequently, methods for computing \u03d5(T)have\\nreceived considerable research interest. Such methods can\\nbe broadly categorized into two classes: those employing an\\nanalytical approach and those following a statistical one. An-\\nalytical methods aim to develop exact formulas for specific\\nclasses of models. A first step in this direction was taken\\nin Ni (2012, Section 4) showing that the expected signature\\nof an It \u02c6o diffusion satisfies an explicit partial differential\\nequation (PDE). This result was subsequently generalized\\nin Cuchiero et al. (2023) to the class of signature-SDEs and\\nin Friz et al. (2022; 2024) to (discontinuous) semimartin-\\ngales. On the other hand, the statistical approach aims to\\nestimate \u03d5(T)directly from observed data, preserving the\\nmodel-free nature of the expected signature. For a given set\\nof observations X1,\u03c0, . . . ,XN,\u03c0one can form the estimator\\n\u02c6\u03d5N,\u03c0(T) :=1\\nNNX\\nn=1S(Xn,\u03c0)[0,T],\\nas illustrated in Figure 1, and study its in-fill |\u03c0| \u21920and\\nlarge-sample N\u2192 \u221e asymptotics. This line of work in-\\ncludes the explicit results of Ni (2012, Section 3.2) for\\nBrownian motion and of Passeggeri (2020) for fractional\\nBrownian motion with Hurst parameter H > 1/2as well\\nas the preliminary results in Friz & Victoir (2010) for more\\ngeneral semimartingales. Additionally, Schell & Oberhauser\\n(2023, Section 8) develops asymptotic results for processes\\nof bounded variation. In this work we provide a unifying set\\nof general conditions under which the expected signature\\nestimator \u02c6\u03d5N,\u03c0(T)displays important asymptotic statistical\\nproperties, namely consistency and asymptotic normality.\\nOur results allow for irregular2observation partitions \u03c0\\n\u2013 possibly varying across samples \u2013 and for dependency\\n2Clearly, for the estimation problem to be well-posed, the se-\\nquence of partitions needs to be signature defining in the sense of\\nDefinition 2.5.across the samples X1,\u03c0, . . . ,Xn,\u03c0. The first main contri-\\nbution of this paper is thus to bridge the gap between the\\nempirical expected signature estimator and the expected\\nsignature of a latent continuous-time stochastic process, un-\\nlocking a more general probabilistic interpretation of several\\nML algorithms and effectively moving beyond the expected\\nsignature as a simple feature extraction method. This natu-\\nrally leads to the second theoretical contribution: by starting\\nfrom the continuous-time setting we devise a modification\\nof the expected signature estimator with significantly bet-\\nter finite sample properties when the latent data generating\\nprocess is a martingale. The superior performance of this\\nmodified estimator is empirically verified through various\\nexperiments with expected signature-based ML algorithms\\nfrom the literature.\\nFigure 1. Estimating the expected signature estimation from a finite\\ncollection of discretely-observed paths.\\n2. Theory\\nLetX={Xt, t\u2208[0, T]}denote a d-dimensional stochas-\\ntic process over the probability space (\u2126,F,P).\\nDefinition 2.1. We say Xis a canonical geometric stochastic\\nprocess of rough order pif there exists a sequence of parti-\\ntions \u03c1with|\u03c1| \u21920such that the limit in the p-variation\\nmetric of the canonically lifted linearly interpolated process\\nX\u03c1exists in probability. Convergence in probability implies\\nalmost sure convergence (along a subsequence) and hence\\nwe can almost surely define the lift of Xas such limit.\\nRemark 2.2.The definition of lift suggests this might de-\\npend on the choice of the sequence of partitions \u03c1. In any\\ncase, for a wide range of stochastic processes there exist\\ncanonical lifts that satisfy our definition of canonical geo-\\nmetric rough path. These include:\\n\u2022Semimartingales: For p\u2208(2,3)any semimartingale\\ncan be lifted to a geometric p-rough path by defining\\nthe lift via Stratonovich integration; the signature of\\nXthen coincides with iterated Stratonovich integrals.\\nFor any sequence of partitions \u03c1the lifts of the linear\\n2\",\"annotations\":null}", "tool_call_id": "toolu_01E5EAuX4T4rTfrTejsSw7Vc"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 48\\nExtracted page range: 1-2\\n\\n=== Page 1 ===\\narXiv:2410.02958v2  [cs.LG]  6 Jun 2025AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\\nPatara Trirat1Wonyong Jeong1Sung Ju Hwang1 2\\nAbstract\\nAutomated machine learning (AutoML) acceler-\\nates AI development by automating tasks in the\\ndevelopment pipeline, such as optimal model\\nsearch and hyperparameter tuning. Existing Au-\\ntoML systems often require technical expertise\\nto set up complex tools, which is in general time-\\nconsuming and requires a large amount of human\\neffort. Therefore, recent works have started ex-\\nploiting large language models (LLM) to lessen\\nsuch burden and increase the usability of AutoML\\nframeworks via a natural language interface, al-\\nlowing non-expert users to build their data-driven\\nsolutions. These methods, however, are usually\\ndesigned only for a particular process in the AI\\ndevelopment pipeline and do not efficiently use\\nthe inherent capacity of the LLMs. This paper pro-\\nposes AutoML-Agent , a novel multi-agent frame-\\nwork tailored for full-pipeline AutoML, i.e., from\\ndata retrieval to model deployment. AutoML-\\nAgent takes user\u2019s task descriptions, facilitates\\ncollaboration between specialized LLM agents,\\nand delivers deployment-ready models. Unlike ex-\\nisting work, instead of devising a single plan, we\\nintroduce a retrieval-augmented planning strategy\\nto enhance exploration to search for more optimal\\nplans. We also decompose each plan into sub-\\ntasks (e.g., data preprocessing and neural network\\ndesign) each of which is solved by a specialized\\nagent we build via prompting executing in parallel,\\nmaking the search process more efficient. More-\\nover, we propose a multi-stage verification to ver-\\nify executed results and guide the code generation\\nLLM in implementing successful solutions. Ex-\\ntensive experiments on seven downstream tasks\\nusing fourteen datasets show that AutoML-Agent\\nachieves a higher success rate in automating the\\nfull AutoML process, yielding systems with good\\nperformance throughout the diverse domains.\\n1DeepAuto.ai2KAIST, Seoul, South Korea. Correspondence\\nto: Sung Ju Hwang <sjhwang@deepauto.ai >.\\nProceedings of the 42ndInternational Conference on Machine\\nLearning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025\\nby the author(s).1. Introduction\\nAutomated machine learning (AutoML) has significantly\\nreduced the need for technical expertise and human labors\\nin developing effective data-driven solutions by automating\\neach process in the AI development pipeline (Yao et al.,\\n2018; Ren et al., 2020; He et al., 2021), such as feature\\nengineering, model selection, and hyperparameter optimiza-\\ntion (HPO). However, current AutoML systems (Gijsbers\\net al., 2024) often necessitate programming expertise to\\nconfigure complex tools and resources, potentially creating\\nbarriers for a larger pool of users with limited skills and\\nknowledge, such as domain experts (Sun et al. (2023); \u00a7A).\\nTo make AutoML frameworks more accessible to non-expert\\nusers, many recent studies (Trirat et al., 2021; Viswanathan\\net al., 2023; Li et al., 2023; Hollmann et al., 2023b; Liu\\net al., 2025; Zhang et al., 2023; Shen et al., 2023; Zhang\\net al., 2024a; Hong et al., 2024a; Guo et al., 2024a; Yang\\net al., 2025; Chi et al., 2024) have suggested to use natural\\nlanguage interfaces with large language models (LLM) for\\nmachine learning (ML) and data science (DS) tasks. Nev-\\nertheless, these previous LLM-based AutoML frameworks\\nonly considered a limited number of tasks due to their re-\\nstricted designs, either only for a process in the pipeline (e.g.,\\nfeature engineering (Hollmann et al., 2023b; Li et al., 2024;\\nMalberg et al., 2024), HPO (Liu et al., 2024a; 2025; Zhang\\net al., 2024a), and model selection (Zhang et al., 2023; Shen\\net al., 2023)) or for a specific group of downstream tasks\\n(e.g., natural language processing (Viswanathan et al., 2023)\\nand computer vision (Yang et al., 2025)). In addition, most\\nmethods overlook the inherent capability of LLMs to search\\nfor promising models by performing actual training of the\\ncandidate models during the search process, making it pro-\\nhibitively costly and slow.\\nFor an AutoML framework to be truly practical, it should\\nperform end-to-end AutoML, considering both the data\\naspects (retrieval, preprocessing, and feature engineering)\\nandmodel aspects (selection, HPO, and deployment). This\\nis because a process in one aspect can affect subsequent\\nprocesses in the other, potentially leading to suboptimal so-\\nlutions when combining results from different frameworks.\\nMeanwhile, the AutoML framework should be computation-\\nally efficient, using strategies to minimize the computational\\noverhead during search. However, there are two main chal-\\nlenges in building such a framework.\\n1\\n\\n=== Page 2 ===\\nAutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\\nHigh Complexity of Planning Tasks The planning of the\\nentire AutoML pipeline introduces extra complexities com-\\npared to task- or problem-specific planning, primarily due to\\nthe inter-dependencies among the steps in the pipeline. For\\nexample, types of retrieved datasets affects how to design\\npreprocessing steps and neural networks. Then, the designed\\nnetwork affects which particular hyper-parameters need to\\nbe optimized depending on the given downstream task. Such\\ninter-step dependencies result in the enlarged search space\\nsince it should consider all possible combinations of inter-\\nrelated steps. Besides, enabling the framework to operate\\nacross various downstream tasks exacerbates these chal-\\nlenges, as each has task-specific requirements.\\nChallenges in Accurate Implementations To develop a\\nmodular and extendable framework that effectively handles\\ndiverse ML tasks, it is crucial to enhance the flexibility of\\nthe LLM agent in its code generation ability, such as by\\ndecoupling the template code from the code for specific\\ndatasets. However, using LLMs to autonomously gener-\\nate complete ML pipelines may lead to hallucination issues,\\nincluding code incompletion, incorrect or missing dependen-\\ncies, and potential undiscovered bugs (Hong et al., 2024b).\\nFurthermore, LLMs often struggle with code generation\\nwhen prompted with ambiguous task descriptions. Thus,\\nwe need accurate analysis of the requirements, and a code-\\ngeneration platform that can adaptively generate code based\\non disambiguated requirements.\\nTo address these challenges, we propose a novel multi-agent\\nframework, AutoML-Agent , for full-pipeline AutoML from\\ndata and model search to evaluation, with strategies to tackle\\nthe complexity of the planning problem as well as accu-\\nrate implementation of code. As illustrated in Figure 1,\\nAutoML-Agent accepts a user\u2019s task description and coordi-\\nnates multiple specialized agents to collaboratively identify\\nan optimal ML pipeline, ultimately delivering a deployment-\\nready model and its inference endpoint as the output.\\nSpecifically, to tackle the complex planning problem, we\\nintroduce a new retrieval-augmented planning strategy\\nequipped with role-specific decomposition and prompting-\\nbased execution. This strategy produces multiple plans\\nbased on retrieved knowledge for a given task description,\\nfacilitating the exploration of promising plans. Moreover, it\\nenables LLM agents to discern global (pipeline-level) and\\nlocal (process-level) relationships among steps through plan\\ndecomposition, which helps them focus on their immediate\\nsub-tasks while aligning with the user\u2019s goal. The retrieval-\\naugmented component also simplifies extending LLMs to\\nvarious downstream tasks using relevant knowledge. The\\nprompting-based execution enhances search efficiency by\\nexploiting LLMs\u2019 in-context learning capabilities without\\nany further training, which could introduce additional cost.\\nTo enhance the accuracy of the implementation, we adopt\\nstructure-based prompt parsing that extracts ML-relevant\\nInput: User's prompt with task description, requirements, and/or constraints \\nAutoML-Agent\\nUser  We need a solution for detecting spam messages within the SMS Spam Collection dataset.\\nGiven the nature of our real-time messaging applicatio n, the model must be lightweight yet\\nefficient, possib ly a streamlined LSTM or GRU architecture . The expected classification accuracy\\nis above 95%, with a latency below 100 milliseconds per message on mobile devices.\\nOutput: Deployable model optimized for the given task and target platform\\nOptimized \\nModelAccuracy : 98.9%\\nInference Latency : ~ 76 ms\\n...\\nData Handling\\n Model Development\\n Deployment\\n Prompt Analysis\\nAgent\\nManagerFigure 1. AutoML-Agent receives user\u2019s instructions and delivers\\noptimized deployable models.\\nrequirements from the user\u2019s description and multi-stage\\nverification that provides feedback between each step in\\nthe framework to ensure the quality of instructions when\\nguiding the LLM for code generation. These modules aim\\nto improve the correctness and clarity of the task description\\nfor code implementation. Our contributions are as follows.\\n\u2022We propose a novel multi-agent LLM framework for Au-\\ntoML, designed to automate the entire AI development\\npipeline. To the best of our knowledge, this is the first at-\\ntempt to employ LLMs in a task-agnostic AutoML frame-\\nwork that spans from data retrieval to model deployment.\\n\u2022We address the challenges due to the complexity of the\\nplanning problem in full-pipeline AutoML by introduc-\\ning retrieval-augmented planning with role-specific plan\\ndecomposition and prompting-based plan execution, en-\\nhancing the flexibility and efficiency of the search process.\\n\u2022To enhance the accuracy of our full-pipeline implemen-\\ntation, we integrate structure-based prompt parsing and\\nmulti-stage verification to ensure the quality of resulting\\nsolutions and instructions prior to actual code implemen-\\ntation, thereby improving overall performance.\\n\u2022We demonstrate the superiority of the proposed AutoML-\\nAgent framework through extensive experiments on seven\\ndownstream tasks using fourteen datasets.\\n\u2022We have made the source code available at https://\\ngithub.com/deepauto-ai/automl-agent .\\n2. Related Work\\nAutoML is a transformative approach for optimizing ML\\nworkflows, enabling both practitioners and researchers to\\nefficiently design models and preprocessing pipelines with\\nminimal manual intervention (Ren et al., 2020; He et al.,\\n2021; Gijsbers et al., 2024). Despite several advancements\\nin AutoML (Jin et al., 2019; Feurer et al., 2022; Tang et al.,\\n2024), most of them are designed only for particular ele-\\nments of the ML pipeline. Only a few works (Bisong, 2019;\\nMukunthu et al., 2019; Microsoft, 2021) support multiple\\n2\",\"annotations\":null}", "tool_call_id": "toolu_01W5pL6wJa3m5YWRi5hHadmA"}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 20\\nExtracted page range: 1-2\\n\\n=== Page 1 ===\\nLearning Smooth and Expressive Interatomic\\nPotentials for Physical Property Prediction\\nXiang Fu1,Brandon M. Wood1,Luis Barroso-Luque1,Daniel S. Levine1,Meng Gao1,Misko Dzamba1,\\nC. Lawrence Zitnick1\\n1Fundamental AI Research (FAIR) at Meta\\nMachine learning interatomic potentials (MLIPs) have become increasingly effective at approximating\\nquantum mechanical calculations at a fraction of the computational cost. However, lower errors\\non held out test sets do not always translate to improved results on downstream physical property\\nprediction tasks. We propose testing MLIPs on their practical ability to conserve energy during\\nmolecular dynamic simulations. If passed, improved correlations are found between test errors and\\ntheir performance on physical property prediction tasks. We identify choices which may lead to\\nmodels failing this test, and use these observations to improve upon highly-expressive models. The\\nresulting model, eSEN, provides state-of-the-art results on a range of physical property prediction tasks,\\nincluding materials stability prediction, thermal conductivity prediction, and phonon calculations.\\nCorrespondence: Xiang Fu ( xiangfu@meta.com ) and C. Lawrence Zitnick ( zitnick@meta.com )\\nCode: https://github.com/facebookresearch/fairchem\\nCheckpoints: https://huggingface.co/facebook/OMAT24\\n1 Introduction\\nDensity Functional Theory (DFT), which models the\\nelectrons in materials and molecules, serves as the\\nfoundation for many modern drug and materials dis-\\ncovery workflows. Unfortunately, DFT calculations\\nare notoriously computationally intensive, scaling\\ncubically with the number of electrons in the sys-\\ntem: O(n3). Machine learning interatomic potentials\\n(MLIPs) are promising in approximating and expe-\\nditing DFT calculations. With increasing data set\\nsizes and model innovations, MLIPs have shown sub-\\nstantial improvements in accuracy and generalization\\ncapabilities (Batatia et al., 2023; Merchant et al.,\\n2023; Yang et al., 2024; Barroso-Luque et al., 2024).\\nPredicting physical properties in chemistry and ma-\\nterials science often requires complex workflows in-\\nvolving numerous evaluations of DFT or MLIPs. For\\nexample, in molecular dynamics (MD) simulations,\\nforces are predicted over thousands to millions of\\ntime steps. However, the MLIP literature has mostly\\nfocused on assessing models based on energy and\\nforce predictions over static DFT test sets rather\\nthan directly assessing their performance in complex\\nsimulations. This approach has limitations, as im-\\nproved accuracy on test sets does not always lead to\\nbetter predictions of physical properties (P\u00f3ta et al.,\\n2024; Loew et al., 2024).In this paper, we address two questions: Why does\\nhigher test accuracy sometimes fail to enhance a\\nmodel\u2019s ability to predict physical properties, and\\nhow can we improve MLIPs to excel in this area? We\\nfirst outline four critical property prediction tasks\\nand identify the properties required for an MLIP\\nto succeed in these tasks. These properties entail\\nlearning a conservative model with continuous and\\nbounded energy derivatives, indicating a smoothly-\\nvarying and physically meaningful energy landscape.\\nTo test whether these properties hold, we propose\\ntesting the ability of MLIPs to practically conserve\\nenergy in MD simulations. We demonstrate models\\nthat pass this test have a higher correlation between\\ntest errors and property prediction accuracy.\\nBuilding on these insights, we present a novel MLIP\\ncalled eSEN and training approach that achieves\\nstate-of-the-art (SOTA) performance on complex\\nproperty prediction tasks. Specifically, our model\\nis capable of running energy-conserving MD simula-\\ntions for out-of-distribution systems (Figure 1 (a)).\\nFor materials stability prediction, eSEN achieves a\\nleading F1 score of 0.831and a \u03baSRMEof0.340on the\\ncompliant Matbench-Discovery benchmark (Riebe-\\nsell et al., 2023; P\u00f3ta et al., 2024). Previous models\\nare only able to excel in one of these metrics ( Fig-\\nure 1 (b,c)). We also achieve a SOTA F1 score of\\n0.925and\u03baSRMEof0.170on the non-compliant cate-\\n1arXiv:2502.12147v2  [physics.comp-ph]  23 Apr 2025\\n\\n=== Page 2 ===\\n(a)(b)\\n(c)(d)Figure 1 (a) Energy conservation in MD simulations.\\nDirect-force models (Orb, eqV2) and CHGNet fail to con-\\nserve. (b) A higher F1 score on the Matbench-Discovery\\nstrongly correlates with a lower test-set energy MAE.\\n(c) Test-set energy MAE and \u03baSRMEon the Matbench-\\nDiscovery benchmark. (d) Test-set energy MAE and vi-\\nbrational entropy MAE on the MDR Phonon benchmark.\\nOur model (eSEN) achieves the best performance on all\\nbenchmarks. A higher correlation between test-set energy\\nMAE and physical property prediction performance can\\nbe observed among energy-conserving models. All models\\nare trained on MPTrj.\\ngory. On the MDR Phonon benchmark (Loew et al.,\\n2024), SOTA results are found (Figure 1 (d)). Fi-\\nnally, eSEN achieves the highest test accuracy on the\\nSPICE-MACE-OFF dataset (Kov\u00e1cs et al., 2023).\\n2 Preliminaries\\n2.1 Machine learning interatomic potentials\\nUnder the Born-Oppenheimer approximation (Op-\\npenheimer, 1927) utilized by DFT (Parr et al., 1979),\\nthe Potential Energy Surface (PES) can be written\\nas a function of positions, r, and atomic numbers, a:\\nE(r,a). Per-atom forces can be calculated by taking\\nthe negative gradient of the PES with respect to the\\natom positions, F=\u2212\u2207 rE. For periodic systems\\nsuch as inorganic materials, the lattice parameters l\\nare also considered ( E(r,a,l)), and the stress \u03c3may\\nalso be calculated, which can be understood as the\\ngradient of the potential energy surface with respect\\nto the lattice parameters.\\nThe goal of an MLIP (Unke et al., 2021b) is to predictthe exact same properties as DFT from a training\\ndataset of DFT calculations (Chanussot et al., 2021;\\nRiebesell et al., 2023; Loew et al., 2024). The most\\nstraightforward benchmark for MLIPs is to evaluate\\nthe model on a held-out test set of DFT calculations,\\nandcomparemodelsbasedonthemeanabsoluteerror\\n(MAE) or root mean squared error (RMSE) of ener-\\ngies, forces, or stresses. To bridge the gap between\\nthese performance metrics and practical applicabil-\\nity, we need to ensure they correlate with physical\\nproperty prediction tasks, such as those described\\nnext.\\n2.2 Physical property prediction tasks\\nGeometry optimization/relaxation. Many computa-\\ntional chemistry and materials science tasks rely on\\natomic systems being in stable configurations, which\\ncorrespond to minima of the PES. Stable states are\\nfound by minimizing the potential energy using an\\noptimization procedure that iteratively updates atom\\npositions based on the predicted forces ( F=\u2212\u2207 rE).\\nGiven that many physical properties are evaluated\\nat or near equilibrium states, geometry optimization\\n(also referred to as \u201crelaxation\u201d) is usually the first\\nstep in most computational workflows.\\nMD simulations. Simulating the time evolution of\\natomic systems enables us to gain understanding of\\nvarious chemical and biological processes, as well as\\nenabling the calculation of macroscopic properties,\\nsuch as liquid densities, that can be experimentally\\nverified. For the task of molecular dynamics simu-\\nlation, we typically use a potential to compute the\\nper-atom forces which are then used to numerically\\nintegrate Newton\u2019s equations of motion. In this work,\\nwe will focus on the microcanonical ensemble (NVE) ,\\nwhere the number of particles (N), the volume of the\\nsystem (V), and the energy of the system (E) are\\nkept constant.\\nPhonon and thermal conductivity calculations. Precise\\npredictions of phonon band structures and vibra-\\ntional modes are essential for understanding various\\nmaterial properties, including dynamical stability,\\nthermal stability Bartel (2022); Fultz (2010), ther-\\nmal conductivity Razeghi (2002), and optoelectronic\\nbehavior Ganose et al. (2021). The calculation of\\nphonon band structures requires the MLIP to accu-\\nrately predict higher-order derivatives and capture\\nthe subtle curvature of the true PES around critical\\npoints. Recent work P\u00f3ta et al. (2024) has demon-\\nstrated the usage of MLIPs in predicting thermal\\nconductivity ( \u03ba) by solving the Wigner transport\\nequation (Simoncelli et al., 2022). In order to accu-\\nrately predict \u03ba, MLIPs must reliably capture both\\n2\",\"annotations\":null}", "tool_call_id": "toolu_01SUgUqxrromgAMGHfN725s3"}, {"role": "assistant", "content": "Perfect! Now I have all the author information from the PDFs. Let me now search for the Google Scholar profiles of each first author:", "tool_calls": [{"id": "toolu_01US2diMme1FWe3nL17zPJkW", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Aaditya K. Singh\\\" UCL Google Scholar\", \"num_results\": 5}"}}, {"id": "toolu_01D84epsEucwphh4McSeyP8p", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Amber Yijia Zheng\\\" Purdue Google Scholar\", \"num_results\": 5}"}}, {"id": "toolu_019dQrZHH5vRnoW5pGThSAxc", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Cl\u00e9ment Bonet\\\" ENSAE Google Scholar\", \"num_results\": 5}"}}, {"id": "toolu_018dyDoWKisPgDCCL3ySG66r", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Lorenzo Lucchese\\\" Imperial College London Google Scholar\", \"num_results\": 5}"}}, {"id": "toolu_01XqssQgehqx1oKV59jbhDdj", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Patara Trirat\\\" DeepAuto Google Scholar\", \"num_results\": 5}"}}, {"id": "toolu_01CCGmGQgm7iYPWwMRjRGw6A", "type": "function", "function": {"name": "local-web_search", "arguments": "{\"query\": \"\\\"Xiang Fu\\\" Meta FAIR Google Scholar\", \"num_results\": 5}"}}]}, {"role": "tool", "content": "Title: Aaditya K Singh\nLink: https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en\nSnippet: Aaditya K Singh. PhD Student, Gatsby Computational Neuroscience Unit, University College London. Verified email at ucl.ac.uk. Machine Learning.\nSitelinks: No sitelinks\n\nTitle: Aaditya K Singh\nLink: https://openreview.net/profile?id=~Aaditya_K_Singh1\nSnippet: Aaditya K Singh. Pronouns: he/him. PhD student, Gatsby Computational Neuroscience Unit, University College London, University of London.\nSitelinks: No sitelinks\n\nTitle: People\nLink: https://www.saxelab.org/people\nSnippet: ORCID | Google Scholar. Next position: Princeton. Portrait. Aaditya K Singh. PhD Student. Google Scholar | Personal website. Next position: OpenAI. Portrait.\nSitelinks: No sitelinks\n\nTitle: Jin Hwa Lee\nLink: https://scholar.google.com/citations?user=QHV2vNgAAAAJ&hl=en\nSnippet: Aaditya K SinghPhD Student, Gatsby Computational Neuroscience Unit, University College LondonVerified email at ucl.ac.uk. Follow.\nSitelinks: No sitelinks\n\nTitle: The Transient Nature of Emergent In-Context Learning in ...\nLink: https://discovery.ucl.ac.uk/10181228/1/8706_the_transient_nature_of_emerge.pdf\nSnippet: by SCY Chan \u00b7 2023 \u00b7 Cited by 61 \u2014 Aaditya K. Singh\u2217. Gatsby Unit, UCL. Stephanie C.Y. Chan\u2217. Google DeepMind ... A.S. is a CIFAR. Azrieli Global Scholar in the Learning in Machines & Brains ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_01US2diMme1FWe3nL17zPJkW"}, {"role": "tool", "content": "Title: Amber Yijia Zheng - Google \u5b66\u672f\u641c\u7d22\nLink: https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN\nSnippet: Amber Yijia Zheng. \u5176\u4ed6\u59d3\u540d Yijia Zheng. PhD Student, Purdue University. \u5728purdue.edu \u7684\u7535\u5b50\u90ae\u4ef6\u7ecf\u8fc7\u9a8c\u8bc1- \u9996\u9875 \u00b7 Generative ModelsDeep Learning.\nSitelinks: No sitelinks\n\nTitle: Cedar Site Bai - Google Scholar\nLink: https://scholar.google.com/citations?user=Vnc1dYAAAAAJ&hl=en\nSnippet: Chuyang KePurdue UniversityVerified email at purdue.edu. Amber Yijia ZhengPhD Student, Purdue UniversityVerified email at purdue.edu.\nSitelinks: No sitelinks\n\nTitle: Amber Yijia Zheng\nLink: https://www.amberyzheng.com/\nSnippet: Amber Yijia Zheng. I am a Ph.D. student in Computer Science at Purdue University, advised by Prof. Raymond A. Yeh. I received my B.Sc. in Data Science from ...\nSitelinks: No sitelinks\n\nTitle: Amber Yijia Zheng - Ph.D. candidate in CS at Purdue\nLink: https://www.linkedin.com/in/amberyzheng\nSnippet: Amber Yijia Zheng. Ph.D. candidate in CS at Purdue. Meta Purdue University. West Lafayette, Indiana, United States. 614 followers 500+ ...\nSitelinks: No sitelinks\n\nTitle: Cedar Site Bai\nLink: https://openreview.net/profile?id=~Site_Bai1\nSnippet: Model Immunization from a Condition Number Perspective \u00b7 Amber Yijia Zheng, Site Bai, Brian Bullins, Raymond A. Yeh. Published: 01 May 2025, Last Modified: 05 ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_01D84epsEucwphh4McSeyP8p"}, {"role": "tool", "content": "Title: Cl\u00e9ment Bonet\nLink: https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en\nSnippet: Anna KorbaENSAE/CRESTVerified email at ensae.fr. Follow. Cl\u00e9ment Bonet. Ecole Polytechnique, CMAP. Verified email at polytechnique.edu ...\nSitelinks: No sitelinks\n\nTitle: Cl\u00e9ment Bonet\nLink: https://scholar.google.fr/citations?user=wjCPk5kAAAAJ&hl=fr\nSnippet: Anna KorbaENSAE/CRESTAdresse e-mail valid\u00e9e de ensae.fr. Suivre. Cl\u00e9ment Bonet. Ecole Polytechnique, CMAP. Adresse e-mail valid\u00e9e de ...\nSitelinks: No sitelinks\n\nTitle: Cl\u00e9ment Bonet\nLink: https://clbonet.github.io/\nSnippet: Cl\u00e9ment Bonet. I am an associate professor at Ecole Polytechnique. My researchs lie at the interface of Optimal Transport, Optimization, ...\nSitelinks: No sitelinks\n\nTitle: Anna Korba - Assistant Professor, Ensae ParisTech\nLink: https://openreview.net/profile?id=~Anna_Korba1\nSnippet: Cl\u00e9ment Bonet \u00b7 Cl\u00e9mentine Chazal \u00b7 Courtney Paquette \u00b7 David Alvarez-Melis \u00b7 David Rohde \u00b7 Eric Moulines \u00b7 Eric Sibony \u00b7 Felipe Llinares-L\u00f3pez \u00b7 Flavien L\u00e9ger ...\nSitelinks: No sitelinks\n\nTitle: Anna Korba \u2013\nLink: https://akorba.github.io/resources/CV_EN.pdf\nSnippet: { Postdocs: 2023-?: Omar Chehab, Adrien Vacher, Cl\u00e9ment Bonet. { Interns: Mahdi Attia (Ensta, M1 student, summer 2022); Adam David (Polytechnique, M2 ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_019dQrZHH5vRnoW5pGThSAxc"}, {"role": "tool", "content": "Title: Lorenzo Lucchese\nLink: https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it\nSnippet: Lorenzo Lucchese. PhD student, Imperial College London. Email verificata su imperial.ac.uk - Home page \u00b7 Mathematics of Random Systems. Articoli ...\nSitelinks: No sitelinks\n\nTitle: Lorenzo Lucchese\nLink: https://openreview.net/profile?id=~Lorenzo_Lucchese1\nSnippet: Lorenzo Lucchese. Pronouns: he/him. Researcher, Quantitative Research, GSA ... Imperial College London (imperial.ac.uk). 2021 \u2013 2024. Undergrad student.\nSitelinks: No sitelinks\n\nTitle: Almut Veraart - PhD students and Postdoctoral researchers\nLink: https://sites.google.com/view/almutveraart/phd-students\nSnippet: Lorenzo Lucchese (Imperial, 2021 - 2025) (CDT: Mathematics of Random Systems) ... Imperial College London). First job after PhD: Quantitative Researcher ...\nSitelinks: No sitelinks\n\nTitle: Mikko S. Pakkanen\nLink: https://scholar.google.com/citations?user=LGkKGsAAAAAJ&hl=en\nSnippet: Lorenzo LucchesePhD student, Imperial College LondonVerified email at imperial.ac.uk. Jose Manuel CorcueraProfesor de ...\nSitelinks: No sitelinks\n\nTitle: \u202aMikko S. Pakkanen\u202c - \u202aGoogle Acad\u00e8mic\u202c\nLink: https://scholar.google.cat/citations?user=LGkKGsAAAAAJ&hl=ca\nSnippet: Associate Professor in Data Science and Quantitative Finance, Imperial College London ... Lorenzo LucchesePhD student, Imperial College LondonCorreu ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_018dyDoWKisPgDCCL3ySG66r"}, {"role": "tool", "content": "Title: Patara Trirat\nLink: https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en\nSnippet: Patara Trirat. Research Scientist at DeepAuto.ai, KAIST. Verified email at kaist.ac.kr - Homepage \u00b7 Agentic AIData MiningAutomated Machine ...\nSitelinks: No sitelinks\n\nTitle: Large language models are zero-shot point-of-interest ...\nLink: https://link.springer.com/article/10.1007/s10618-025-01148-w\nSnippet: DeepAuto.ai, Seoul, Republic of Korea. Patara Trirat. Authors. Joeun Kim. View author publications. Search author on:PubMed Google Scholar.\nSitelinks: No sitelinks\n\nTitle: Youngeun Nam\nLink: https://scholar.google.com/citations?user=Cz1zyRsAAAAJ&hl=en\nSnippet: Patara TriratResearch Scientist at DeepAuto.ai, KAISTVerified email at kaist.ac.kr. Susik YoonKorea UniversityVerified email at ...\nSitelinks: No sitelinks\n\nTitle: Probabilistic Wind Power Forecasting Using Optimised ...\nLink: https://www.researchgate.net/publication/359412033_Probabilistic_Wind_Power_Forecasting_Using_Optimised_Deep_Auto-Regressive_Recurrent_Neural_Networks\nSnippet: Patara Trirat \u00b7 Jae-Gil Lee. Time-series anomaly detection uncovers rare errors or intriguing events of interest that significantly deviate from normal ...\nSitelinks: No sitelinks\n\nTitle: Automating Code Generation from Scientific Papers in ...\nLink: https://arxiv.org/pdf/2504.17192\nSnippet: by M Seo \u00b7 2025 \u00b7 Cited by 16 \u2014 [41] Patara Trirat, Wonyong Jeong, and Sung Ju Hwang. Automl-agent: A multi-agent llm framework for full-pipeline automl, 2024. URL https ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_01XqssQgehqx1oKV59jbhDdj"}, {"role": "tool", "content": "Title: Xiang Fu\nLink: https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en\nSnippet: Muhammed ShuaibiResearch Engineer, FAIR, MetaVerified email at meta.com ... Xiang Fu. Periodic Labs. Verified email at periodic.com - Homepage \u00b7 machine ...\nSitelinks: No sitelinks\n\nTitle: Xiang Fu\nLink: https://xiangfu.co/\nSnippet: Xiang Fu \u4ed8\u8944 ... Member of Technical Staff at Periodic Labs. Previously at Meta FAIR. I completed my PhD at MIT CSAIL, advised by Tommi Jaakkola with additional ...\nSitelinks: No sitelinks\n\nTitle: Xiang Fu\nLink: https://openreview.net/profile?id=~Xiang_Fu4\nSnippet: Xiang Fu. Research Scientist, FAIR at Meta. Joined February 2020. Names. Xiang Fu (Preferred). Suggest Name. Emails. ****@mit.edu (Confirmed).\nSitelinks: No sitelinks\n\nTitle: [2410.12771] Open Materials 2024 (OMat24) Inorganic ...\nLink: https://arxiv.org/abs/2410.12771\nSnippet: by L Barroso-Luque \u00b7 2024 \u00b7 Cited by 137 \u2014 Title:Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models. Authors:Luis Barroso-Luque, Muhammed Shuaibi, Xiang Fu, Brandon M.\nSitelinks: No sitelinks\n\nTitle: [2506.23971] UMA: A Family of Universal Models for Atoms\nLink: https://arxiv.org/abs/2506.23971\nSnippet: by BM Wood \u00b7 2025 \u00b7 Cited by 29 \u2014 Title:UMA: A Family of Universal Models for Atoms. Authors:Brandon M. Wood, Misko Dzamba, Xiang Fu ... To address this need, Meta FAIR ...\nSitelinks: No sitelinks\n", "tool_call_id": "toolu_01CCGmGQgm7iYPWwMRjRGw6A"}, {"role": "assistant", "content": "Excellent! Now I have all the information I need. Let me compile the data and fill in the Excel spreadsheet:", "tool_calls": [{"id": "toolu_01QQ31amGuyS6mEBLFrEfYGS", "type": "function", "function": {"name": "excel-write_data_to_excel", "arguments": "{\"filepath\": \"/workspace/dumps/workspace/paper_initial.xlsx\", \"sheet_name\": \"Sheet1\", \"start_cell\": \"B2\", \"data\": [[\"Aaditya K. Singh\",\"Gatsby Computational Neuroscience Unit, University College London\",\"https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en\"],[\"Amber Yijia Zheng\",\"Department of Computer Science, Purdue University\",\"https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN\"],[\"Cl\u00e9ment Bonet\",\"ENSAE, CREST, IP Paris\",\"https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en\"],[\"Lorenzo Lucchese\",\"Department of Mathematics, Imperial College London, London, United Kingdom\",\"https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it\"],[\"Patara Trirat\",\"DeepAuto.ai\",\"https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en\"],[\"Xiang Fu\",\"Fundamental AI Research (FAIR) at Meta\",\"https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en\"]]}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"Data written to Sheet1\",\"annotations\":null}", "tool_call_id": "toolu_01QQ31amGuyS6mEBLFrEfYGS"}, {"role": "assistant", "content": "Perfect! Let me verify the data was written correctly:", "tool_calls": [{"id": "toolu_01VCx4PvMi7gzFGNAgcPCD1n", "type": "function", "function": {"name": "excel-read_data_from_excel", "arguments": "{\"filepath\": \"/workspace/dumps/workspace/paper_initial.xlsx\", \"sheet_name\": \"Sheet1\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"range\\\": \\\"A1:D7\\\",\\n  \\\"sheet_name\\\": \\\"Sheet1\\\",\\n  \\\"cells\\\": [\\n    {\\n      \\\"address\\\": \\\"A1\\\",\\n      \\\"value\\\": \\\"Title\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B1\\\",\\n      \\\"value\\\": \\\"First Author\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C1\\\",\\n      \\\"value\\\": \\\"Affiliation\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D1\\\",\\n      \\\"value\\\": \\\"Google Scholar Profile\\\",\\n      \\\"row\\\": 1,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A2\\\",\\n      \\\"value\\\": \\\"Strategy Coopetition Explains the Emergence and Transience of In-Context Learning\\\",\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B2\\\",\\n      \\\"value\\\": \\\"Aaditya K. Singh\\\",\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C2\\\",\\n      \\\"value\\\": \\\"Gatsby Computational Neuroscience Unit, University College London\\\",\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D2\\\",\\n      \\\"value\\\": \\\"https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en\\\",\\n      \\\"row\\\": 2,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A3\\\",\\n      \\\"value\\\": \\\"Model Immunization from a Condition Number Perspective\\\",\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B3\\\",\\n      \\\"value\\\": \\\"Amber Yijia Zheng\\\",\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C3\\\",\\n      \\\"value\\\": \\\"Department of Computer Science, Purdue University\\\",\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D3\\\",\\n      \\\"value\\\": \\\"https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN\\\",\\n      \\\"row\\\": 3,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A4\\\",\\n      \\\"value\\\": \\\"Flowing Datasets with Wasserstein over Wasserstein Gradient Flows\\\",\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B4\\\",\\n      \\\"value\\\": \\\"Cl\\\\u00e9ment Bonet\\\",\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C4\\\",\\n      \\\"value\\\": \\\"ENSAE, CREST, IP Paris\\\",\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D4\\\",\\n      \\\"value\\\": \\\"https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en\\\",\\n      \\\"row\\\": 4,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A5\\\",\\n      \\\"value\\\": \\\"Learning with Expected Signatures: Theory and Applications\\\",\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B5\\\",\\n      \\\"value\\\": \\\"Lorenzo Lucchese\\\",\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C5\\\",\\n      \\\"value\\\": \\\"Department of Mathematics, Imperial College London, London, United Kingdom\\\",\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D5\\\",\\n      \\\"value\\\": \\\"https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it\\\",\\n      \\\"row\\\": 5,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A6\\\",\\n      \\\"value\\\": \\\"AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\\\",\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B6\\\",\\n      \\\"value\\\": \\\"Patara Trirat\\\",\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C6\\\",\\n      \\\"value\\\": \\\"DeepAuto.ai\\\",\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D6\\\",\\n      \\\"value\\\": \\\"https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en\\\",\\n      \\\"row\\\": 6,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"A7\\\",\\n      \\\"value\\\": \\\"Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction\\\",\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 1,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"B7\\\",\\n      \\\"value\\\": \\\"Xiang Fu\\\",\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 2,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"C7\\\",\\n      \\\"value\\\": \\\"Fundamental AI Research (FAIR) at Meta\\\",\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 3,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    },\\n    {\\n      \\\"address\\\": \\\"D7\\\",\\n      \\\"value\\\": \\\"https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en\\\",\\n      \\\"row\\\": 7,\\n      \\\"column\\\": 4,\\n      \\\"validation\\\": {\\n        \\\"has_validation\\\": false\\n      }\\n    }\\n  ]\\n}\",\"annotations\":null}", "tool_call_id": "toolu_01VCx4PvMi7gzFGNAgcPCD1n"}, {"role": "assistant", "content": "Perfect! All the information has been successfully filled in. Let me create a summary of what was completed:\n\n## Summary\n\nI have successfully completed the research task for all 6 papers in your Excel sheet. Here's what I found for each paper:\n\n### 1. **Strategy Coopetition Explains the Emergence and Transience of In-Context Learning**\n- **First Author:** Aaditya K. Singh\n- **Affiliation:** Gatsby Computational Neuroscience Unit, University College London\n- **Google Scholar:** https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en\n\n### 2. **Model Immunization from a Condition Number Perspective**\n- **First Author:** Amber Yijia Zheng\n- **Affiliation:** Department of Computer Science, Purdue University\n- **Google Scholar:** https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN\n\n### 3. **Flowing Datasets with Wasserstein over Wasserstein Gradient Flows**\n- **First Author:** Cl\u00e9ment Bonet\n- **Affiliation:** ENSAE, CREST, IP Paris\n- **Google Scholar:** https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en\n\n### 4. **Learning with Expected Signatures: Theory and Applications**\n- **First Author:** Lorenzo Lucchese\n- **Affiliation:** Department of Mathematics, Imperial College London, London, United Kingdom\n- **Google Scholar:** https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it\n\n### 5. **AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML**\n- **First Author:** Patara Trirat\n- **Affiliation:** DeepAuto.ai\n- **Google Scholar:** https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en\n\n### 6. **Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction**\n- **First Author:** Xiang Fu\n- **Affiliation:** Fundamental AI Research (FAIR) at Meta\n- **Google Scholar:** https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en\n\nAll information has been extracted directly from the papers and filled into your Excel spreadsheet at `/workspace/dumps/workspace/paper_initial.xlsx`."}]}